{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0205c45",
   "metadata": {
    "papermill": {
     "duration": 0.008161,
     "end_time": "2025-07-10T07:03:17.319865",
     "exception": false,
     "start_time": "2025-07-10T07:03:17.311704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc3a16a",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-07-10T07:03:17.334540Z",
     "iopub.status.busy": "2025-07-10T07:03:17.334194Z",
     "iopub.status.idle": "2025-07-10T07:03:27.268984Z",
     "shell.execute_reply": "2025-07-10T07:03:27.267857Z"
    },
    "papermill": {
     "duration": 9.944224,
     "end_time": "2025-07-10T07:03:27.270961",
     "exception": false,
     "start_time": "2025-07-10T07:03:17.326737",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn==1.5.2 koolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce67c07b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:03:27.287531Z",
     "iopub.status.busy": "2025-07-10T07:03:27.287148Z",
     "iopub.status.idle": "2025-07-10T07:03:37.960840Z",
     "shell.execute_reply": "2025-07-10T07:03:37.959607Z"
    },
    "papermill": {
     "duration": 10.683992,
     "end_time": "2025-07-10T07:03:37.962648",
     "exception": false,
     "start_time": "2025-07-10T07:03:27.278656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnaive_bayes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GaussianNB\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdiscriminant_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import joblib\n",
    "import shutil\n",
    "import glob\n",
    "import json\n",
    "from itertools import combinations\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.feature_selection import mutual_info_regression, SelectKBest, f_classif\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer  # CRITICAL: Added for missing value handling\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# External libraries with error handling\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "except ImportError:\n",
    "    print(\"CatBoost not available, installing...\")\n",
    "    !pip install catboost\n",
    "    from catboost import CatBoostClassifier\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "except ImportError:\n",
    "    print(\"LightGBM not available, installing...\")\n",
    "    !pip install lightgbm\n",
    "    from lightgbm import LGBMClassifier\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except ImportError:\n",
    "    print(\"XGBoost not available, installing...\")\n",
    "    !pip install xgboost\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "try:\n",
    "    from koolbox import Trainer\n",
    "except ImportError:\n",
    "    print(\"koolbox not available, will use manual cross-validation\")\n",
    "    Trainer = None\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "except ImportError:\n",
    "    print(\"Optuna not available, installing...\")\n",
    "    !pip install optuna\n",
    "    import optuna\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Scipy imports\n",
    "from scipy.special import logit\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939ae04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:03:37.981528Z",
     "iopub.status.busy": "2025-07-10T07:03:37.980369Z",
     "iopub.status.idle": "2025-07-10T07:03:37.987769Z",
     "shell.execute_reply": "2025-07-10T07:03:37.986670Z"
    },
    "papermill": {
     "duration": 0.018386,
     "end_time": "2025-07-10T07:03:37.989403",
     "exception": false,
     "start_time": "2025-07-10T07:03:37.971017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # Kaggle paths (change these for local environment if needed)\n",
    "    train_path = '/kaggle/input/playground-series-s5e7/train.csv'\n",
    "    test_path = '/kaggle/input/playground-series-s5e7/test.csv'\n",
    "    sample_sub_path = '/kaggle/input/playground-series-s5e7/sample_submission.csv'\n",
    "    \n",
    "    # Original dataset path (if available)\n",
    "    original_path = '/kaggle/input/extrovert-vs-introvert-behavior-data-backup/personality_dataset.csv'\n",
    "    \n",
    "    # For local testing, uncomment these lines:\n",
    "    # train_path = 'playground-series-s5e7/train.csv'\n",
    "    # test_path = 'playground-series-s5e7/test.csv'\n",
    "    # sample_sub_path = 'playground-series-s5e7/sample_submission.csv'\n",
    "    # original_path = 'introvert vs extrovert/personality_dataset.csv'\n",
    "    \n",
    "    target = 'Personality'\n",
    "    n_folds = 5  # Balanced for Kaggle runtime\n",
    "    seed = 42\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=n_folds, random_state=seed, shuffle=True)\n",
    "    metric = accuracy_score\n",
    "    \n",
    "    # Hyperparameter optimization settings\n",
    "    n_optuna_trials = 100  # Reduced for Kaggle runtime\n",
    "    n_startup_trials = 20\n",
    "    \n",
    "    # Feature engineering settings\n",
    "    create_interaction_features = True\n",
    "    create_polynomial_features = False  # Disabled to avoid NaN issues\n",
    "    poly_degree = 2\n",
    "    \n",
    "    # Ensemble settings\n",
    "    use_stacking = True\n",
    "    use_blending = True\n",
    "    ensemble_weights_optimization = True\n",
    "    \n",
    "    # Missing value handling\n",
    "    handle_missing_values = True\n",
    "    imputation_strategy = 'median'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8de5d1",
   "metadata": {
    "papermill": {
     "duration": 0.00723,
     "end_time": "2025-07-10T07:03:38.004121",
     "exception": false,
     "start_time": "2025-07-10T07:03:37.996891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346bb7c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:03:38.020690Z",
     "iopub.status.busy": "2025-07-10T07:03:38.020326Z",
     "iopub.status.idle": "2025-07-10T07:03:38.096996Z",
     "shell.execute_reply": "2025-07-10T07:03:38.096072Z"
    },
    "papermill": {
     "duration": 0.087117,
     "end_time": "2025-07-10T07:03:38.098751",
     "exception": false,
     "start_time": "2025-07-10T07:03:38.011634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(CFG.train_path, index_col='id')\n",
    "test = pd.read_csv(CFG.test_path, index_col='id')\n",
    "\n",
    "train[\"Stage_fear\"] = train[\"Stage_fear\"].map({\"No\": 0, \"Yes\": 1})\n",
    "train[\"Drained_after_socializing\"] = train[\"Drained_after_socializing\"].map({\"No\": 0, \"Yes\": 1})\n",
    "\n",
    "test[\"Stage_fear\"] = test[\"Stage_fear\"].map({\"No\": 0, \"Yes\": 1})\n",
    "test[\"Drained_after_socializing\"] = test[\"Drained_after_socializing\"].map({\"No\": 0, \"Yes\": 1})\n",
    "\n",
    "train[CFG.target] = train[CFG.target].map({\"Extrovert\": 0, \"Introvert\": 1})\n",
    "\n",
    "X = train.drop(CFG.target, axis=1)\n",
    "y = train[CFG.target]\n",
    "X_test = test\n",
    "\n",
    "print(f\"Training data shape: {X.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "print(f\"Missing values in train: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in test: {X_test.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced_feature_engineering",
   "metadata": {},
   "source": [
    "# Advanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_engineering_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, create_interactions=True, create_polynomial=True, poly_degree=2, create_statistical=True):\n",
    "        self.create_interactions = create_interactions\n",
    "        self.create_polynomial = create_polynomial\n",
    "        self.poly_degree = poly_degree\n",
    "        self.create_statistical = create_statistical\n",
    "        self.feature_names_ = None\n",
    "        self.poly_features_ = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names_ = list(X.columns)\n",
    "        \n",
    "        if self.create_polynomial:\n",
    "            # Only use numerical features for polynomial\n",
    "            numerical_cols = X.select_dtypes(include=[np.number]).columns\n",
    "            self.poly_features_ = PolynomialFeatures(degree=self.poly_degree, include_bias=False, interaction_only=False)\n",
    "            self.poly_features_.fit(X[numerical_cols])\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_new = X.copy()\n",
    "        \n",
    "        # Create interaction features\n",
    "        if self.create_interactions:\n",
    "            # Social interaction score\n",
    "            X_new['social_interaction_score'] = (X_new['Social_event_attendance'] * X_new['Friends_circle_size']) / (X_new['Time_spent_Alone'] + 1)\n",
    "            \n",
    "            # Extroversion indicator\n",
    "            X_new['extroversion_indicator'] = (X_new['Social_event_attendance'] + X_new['Going_outside'] + X_new['Post_frequency']) / 3\n",
    "            \n",
    "            # Introversion indicator  \n",
    "            X_new['introversion_indicator'] = X_new['Time_spent_Alone'] + X_new['Stage_fear'] + X_new['Drained_after_socializing']\n",
    "            \n",
    "            # Social vs alone ratio\n",
    "            X_new['social_alone_ratio'] = X_new['Social_event_attendance'] / (X_new['Time_spent_Alone'] + 1)\n",
    "            \n",
    "            # Activity level\n",
    "            X_new['activity_level'] = X_new['Going_outside'] + X_new['Social_event_attendance'] + X_new['Post_frequency']\n",
    "            \n",
    "            # Social comfort\n",
    "            X_new['social_comfort'] = X_new['Friends_circle_size'] * (1 - X_new['Stage_fear']) * (1 - X_new['Drained_after_socializing'])\n",
    "            \n",
    "            # ADVANCED FEATURES FOR HIGHER PERFORMANCE\n",
    "            # Personality ratios and interactions\n",
    "            X_new['extroversion_ratio'] = (\n",
    "                X_new['Social_event_attendance'] + X_new['Going_outside'] + X_new['Post_frequency']\n",
    "            ) / (X_new['Time_spent_Alone'] + X_new['Stage_fear'] + X_new['Drained_after_socializing'] + 1)\n",
    "            \n",
    "            # Social confidence score\n",
    "            X_new['social_confidence'] = (\n",
    "                X_new['Friends_circle_size'] * (1 - X_new['Stage_fear']) * \n",
    "                X_new['Social_event_attendance'] / (X_new['Time_spent_Alone'] + 1)\n",
    "            )\n",
    "            \n",
    "            # Energy level indicator\n",
    "            X_new['energy_level'] = (\n",
    "                X_new['Going_outside'] + X_new['Post_frequency'] - \n",
    "                X_new['Drained_after_socializing'] * 2\n",
    "            )\n",
    "            \n",
    "            # Social vs digital preference\n",
    "            X_new['social_vs_digital'] = (\n",
    "                X_new['Social_event_attendance'] - X_new['Post_frequency']\n",
    "            )\n",
    "            \n",
    "            # Comfort zone indicator\n",
    "            X_new['comfort_zone'] = (\n",
    "                X_new['Time_spent_Alone'] + X_new['Stage_fear'] * 2\n",
    "            ) / (X_new['Friends_circle_size'] + 1)\n",
    "            \n",
    "            # Behavioral consistency score\n",
    "            X_new['behavioral_consistency'] = (\n",
    "                abs(X_new['Social_event_attendance'] - X_new['Going_outside']) + \n",
    "                abs(X_new['Post_frequency'] - X_new['Social_event_attendance'])\n",
    "            ) / 2\n",
    "            \n",
    "            # Social engagement intensity\n",
    "            X_new['social_engagement'] = (\n",
    "                X_new['Social_event_attendance'] * X_new['Friends_circle_size'] * \n",
    "                X_new['Post_frequency'] / (X_new['Stage_fear'] + 1)\n",
    "            )\n",
    "            \n",
    "        return X_new\n",
    "\n",
    "# CRITICAL FIX: Handle missing values before feature engineering\n",
    "print(\"Handling missing values...\")\n",
    "if CFG.handle_missing_values:\n",
    "    # Fill missing values\n",
    "    imputer = SimpleImputer(strategy=CFG.imputation_strategy)\n",
    "    numerical_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    if len(numerical_cols) > 0:\n",
    "        X[numerical_cols] = imputer.fit_transform(X[numerical_cols])\n",
    "        X_test[numerical_cols] = imputer.transform(X_test[numerical_cols])\n",
    "    \n",
    "    # Fill any remaining missing values\n",
    "    X = X.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "    \n",
    "    print(f\"Missing values after imputation (train): {X.isnull().sum().sum()}\")\n",
    "    print(f\"Missing values after imputation (test): {X_test.isnull().sum().sum()}\")\n",
    "\n",
    "# Apply feature engineering\n",
    "feature_engineer = AdvancedFeatureEngineer(\n",
    "    create_interactions=CFG.create_interaction_features,\n",
    "    create_polynomial=CFG.create_polynomial_features,\n",
    "    poly_degree=CFG.poly_degree\n",
    ")\n",
    "\n",
    "X_engineered = feature_engineer.fit_transform(X)\n",
    "X_test_engineered = feature_engineer.transform(X_test)\n",
    "\n",
    "print(f\"Original features: {X.shape[1]}\")\n",
    "print(f\"Engineered features: {X_engineered.shape[1]}\")\n",
    "print(f\"New features added: {X_engineered.shape[1] - X.shape[1]}\")\n",
    "print(f\"Final missing values check (train): {X_engineered.isnull().sum().sum()}\")\n",
    "print(f\"Final missing values check (test): {X_test_engineered.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual_cv_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Cross-Validation Function (backup for koolbox)\n",
    "def manual_cv_train(model, X, y, X_test, cv, model_name):\n",
    "    \"\"\"Manual cross-validation training function\"\"\"\n",
    "    oof_preds = np.zeros(len(X))\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    fold_scores = []\n",
    "    \n",
    "    print(f\"Training {model_name} with {cv.n_splits}-fold CV...\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train_fold = X.iloc[train_idx]\n",
    "        y_train_fold = y.iloc[train_idx]\n",
    "        X_val_fold = X.iloc[val_idx]\n",
    "        y_val_fold = y.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predict validation\n",
    "        val_preds = model.predict_proba(X_val_fold)[:, 1]\n",
    "        oof_preds[val_idx] = val_preds\n",
    "        \n",
    "        # Predict test\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / cv.n_splits\n",
    "        \n",
    "        # Calculate fold score\n",
    "        fold_score = accuracy_score(y_val_fold, (val_preds > 0.5).astype(int))\n",
    "        fold_scores.append(fold_score)\n",
    "        \n",
    "        print(f\"  Fold {fold + 1}: {fold_score:.6f}\")\n",
    "    \n",
    "    mean_score = np.mean(fold_scores)\n",
    "    std_score = np.std(fold_scores)\n",
    "    print(f\"  {model_name} CV: {mean_score:.6f} ± {std_score:.6f}\")\n",
    "    \n",
    "    return oof_preds, test_preds, fold_scores\n",
    "\n",
    "# Initialize storage for results\n",
    "scores = {}\n",
    "oof_pred_probs = {}\n",
    "test_pred_probs = {}\n",
    "\n",
    "print(\"Manual CV function and storage initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ensemble_optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE OPTIMIZATION FUNCTIONS\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def optimize_ensemble_weights(oof_predictions, y_true):\n",
    "    \"\"\"Find optimal weights for ensemble\"\"\"\n",
    "    \n",
    "    def objective(weights):\n",
    "        # Normalize weights to sum to 1\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        # Create weighted ensemble prediction\n",
    "        ensemble_pred = np.zeros(len(y_true))\n",
    "        for i, (model_name, oof_pred) in enumerate(oof_predictions.items()):\n",
    "            ensemble_pred += weights[i] * oof_pred\n",
    "        \n",
    "        # Convert to binary predictions and calculate accuracy\n",
    "        binary_pred = (ensemble_pred > 0.5).astype(int)\n",
    "        return -accuracy_score(y_true, binary_pred)  # Negative because we minimize\n",
    "    \n",
    "    # Initial weights (equal)\n",
    "    n_models = len(oof_predictions)\n",
    "    initial_weights = np.ones(n_models) / n_models\n",
    "    \n",
    "    # Constraints: weights sum to 1 and are non-negative\n",
    "    constraints = {'type': 'eq', 'fun': lambda w: w.sum() - 1}\n",
    "    bounds = [(0, 1) for _ in range(n_models)]\n",
    "    \n",
    "    # Optimize\n",
    "    result = minimize(objective, initial_weights, method='SLSQP', \n",
    "                     bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    optimal_weights = result.x / result.x.sum()\n",
    "    \n",
    "    print(\"\\n=== OPTIMAL ENSEMBLE WEIGHTS ===\")\n",
    "    for i, (model_name, weight) in enumerate(zip(oof_predictions.keys(), optimal_weights)):\n",
    "        print(f\"  {model_name}: {weight:.4f}\")\n",
    "    \n",
    "    return optimal_weights\n",
    "\n",
    "def find_optimal_threshold(oof_predictions, y_true):\n",
    "    \"\"\"Find optimal threshold for binary classification\"\"\"\n",
    "    \n",
    "    # Try different thresholds\n",
    "    thresholds = np.arange(0.3, 0.8, 0.01)\n",
    "    best_score = 0\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        predictions = (oof_predictions > threshold).astype(int)\n",
    "        score = accuracy_score(y_true, predictions)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    print(f\"\\n=== OPTIMAL THRESHOLD ===\")\n",
    "    print(f\"Optimal threshold: {best_threshold:.3f} (Score: {best_score:.6f})\")\n",
    "    return best_threshold\n",
    "\n",
    "print(\"Ensemble optimization functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64928fce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:03:38.115250Z",
     "iopub.status.busy": "2025-07-10T07:03:38.114552Z",
     "iopub.status.idle": "2025-07-10T07:03:38.589778Z",
     "shell.execute_reply": "2025-07-10T07:03:38.588732Z"
    },
    "papermill": {
     "duration": 0.485483,
     "end_time": "2025-07-10T07:03:38.591443",
     "exception": false,
     "start_time": "2025-07-10T07:03:38.105960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "corr_train = train.corr()\n",
    "mask_train = np.triu(np.ones_like(corr_train, dtype=bool), k=1)\n",
    "\n",
    "sns.heatmap(\n",
    "    data=corr_train,\n",
    "    annot=True,\n",
    "    fmt='.4f',\n",
    "    mask=mask_train,\n",
    "    square=True,\n",
    "    cmap='coolwarm',\n",
    "    annot_kws={'size': 8},\n",
    "    cbar=False\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d805ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:03:38.610122Z",
     "iopub.status.busy": "2025-07-10T07:03:38.609791Z",
     "iopub.status.idle": "2025-07-10T07:03:39.646926Z",
     "shell.execute_reply": "2025-07-10T07:03:39.645804Z"
    },
    "papermill": {
     "duration": 1.048384,
     "end_time": "2025-07-10T07:03:39.648736",
     "exception": false,
     "start_time": "2025-07-10T07:03:38.600352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mutual_info = mutual_info_regression(X.fillna(0), y, random_state=CFG.seed)\n",
    "\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X.columns\n",
    "mutual_info = pd.DataFrame(mutual_info.sort_values(ascending=False), columns=['Mutual Information'])\n",
    "mutual_info.style.bar(subset=['Mutual Information'], cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621e60e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:03:39.668419Z",
     "iopub.status.busy": "2025-07-10T07:03:39.668065Z",
     "iopub.status.idle": "2025-07-10T07:03:39.765399Z",
     "shell.execute_reply": "2025-07-10T07:03:39.764545Z"
    },
    "papermill": {
     "duration": 0.10987,
     "end_time": "2025-07-10T07:03:39.767668",
     "exception": false,
     "start_time": "2025-07-10T07:03:39.657798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(CFG.train_path, index_col='id')\n",
    "test = pd.read_csv(CFG.test_path, index_col='id')\n",
    "\n",
    "# Reference: https://www.kaggle.com/code/paddykb/ps-s5e7-don-t-look-at-me\n",
    "original = pd.read_csv(CFG.original_path)\n",
    "original = original.rename(columns={'Personality': 'match_p'})\n",
    "original = original.drop_duplicates(['Time_spent_Alone', 'Stage_fear', 'Social_event_attendance', 'Going_outside', 'Drained_after_socializing', 'Friends_circle_size', 'Post_frequency'])\n",
    "train = train.merge(original, how='left')\n",
    "test = test.merge(original, how='left')\n",
    "\n",
    "cat_cols = [\"Stage_fear\", \"Drained_after_socializing\"]\n",
    "train[cat_cols] = train[cat_cols].fillna(\"missing\").astype(\"category\")\n",
    "test[cat_cols] = test[cat_cols].fillna(\"missing\").astype(\"category\")\n",
    "\n",
    "train[CFG.target] = train[CFG.target].map({\"Extrovert\": 0, \"Introvert\": 1})\n",
    "train[\"match_p\"] = train[\"match_p\"].map({\"Extrovert\": 0, \"Introvert\": 1})\n",
    "test[\"match_p\"] = test[\"match_p\"].map({\"Extrovert\": 0, \"Introvert\": 1})\n",
    "\n",
    "X = train.drop(CFG.target, axis=1)\n",
    "y = train[CFG.target]\n",
    "X_test = test\n",
    "_X_test = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c541c0c",
   "metadata": {
    "papermill": {
     "duration": 0.008509,
     "end_time": "2025-07-10T07:03:39.785331",
     "exception": false,
     "start_time": "2025-07-10T07:03:39.776822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e976e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:03:39.803986Z",
     "iopub.status.busy": "2025-07-10T07:03:39.803666Z",
     "iopub.status.idle": "2025-07-10T07:03:39.809825Z",
     "shell.execute_reply": "2025-07-10T07:03:39.808891Z"
    },
    "papermill": {
     "duration": 0.01718,
     "end_time": "2025-07-10T07:03:39.811319",
     "exception": false,
     "start_time": "2025-07-10T07:03:39.794139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_submission(name, X_test, test_pred_probs, score, threshold=0.5):\n",
    "    \"\"\"Save submission with proper format and optional match_p logic\"\"\"\n",
    "    # Load sample submission to get the correct format with id column\n",
    "    sub = pd.read_csv(CFG.sample_sub_path)\n",
    "    \n",
    "    # Make sure we have the same number of predictions as test samples\n",
    "    if len(test_pred_probs) != len(sub):\n",
    "        print(f\"Warning: Prediction length ({len(test_pred_probs)}) != submission length ({len(sub)})\")\n",
    "    \n",
    "    # Create predictions\n",
    "    predictions = (test_pred_probs > threshold).astype(int)\n",
    "    \n",
    "    # Handle match_p logic if available\n",
    "    if hasattr(X_test, 'match_p') and 'match_p' in X_test.columns:\n",
    "        print(f\"Applying match_p logic for {name}...\")\n",
    "        # Apply match_p logic\n",
    "        predictions[X_test.match_p == 0] = 1\n",
    "        predictions[X_test.match_p == 1] = 0\n",
    "    else:\n",
    "        print(f\"No match_p column found, using standard predictions for {name}\")\n",
    "    \n",
    "    # Map to string labels and assign to submission\n",
    "    sub[CFG.target] = pd.Series(predictions).map({0: \"Extrovert\", 1: \"Introvert\"})\n",
    "    \n",
    "    # Save with proper format (id column will be preserved)\n",
    "    filename = f'sub_{name}_{score:.6f}.csv'\n",
    "    sub.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"✅ Submission saved: {filename}\")\n",
    "    print(f\"   Shape: {sub.shape}\")\n",
    "    print(f\"   Columns: {list(sub.columns)}\")\n",
    "    print(f\"   Predictions: {sub[CFG.target].value_counts().to_dict()}\")\n",
    "    \n",
    "    return sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f3d6a2",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-07-10T07:03:39.830301Z",
     "iopub.status.busy": "2025-07-10T07:03:39.829977Z",
     "iopub.status.idle": "2025-07-10T07:03:39.839951Z",
     "shell.execute_reply": "2025-07-10T07:03:39.838948Z"
    },
    "papermill": {
     "duration": 0.021395,
     "end_time": "2025-07-10T07:03:39.841539",
     "exception": false,
     "start_time": "2025-07-10T07:03:39.820144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cb_params = {\n",
    "    \"border_count\": 39,\n",
    "    \"colsample_bylevel\": 0.19459088572914465,\n",
    "    \"depth\": 2,\n",
    "    \"iterations\": 1467,\n",
    "    \"l2_leaf_reg\": 31.236169478676036,\n",
    "    \"learning_rate\": 0.06852669420904771,\n",
    "    \"min_child_samples\": 160,\n",
    "    \"random_state\": 42,\n",
    "    \"random_strength\": 0.8517786189616939,\n",
    "    \"scale_pos_weight\": 1.1691394390533685,\n",
    "    \"subsample\": 0.3192330024411618,\n",
    "    \"verbose\": False,\n",
    "    \"cat_features\": cat_cols\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    \"colsample_bylevel\": 0.8168489864941239,\n",
    "    \"colsample_bynode\": 0.8850485490950061,\n",
    "    \"colsample_bytree\": 0.8379339940113913,\n",
    "    \"gamma\": 2.3977359439809276,\n",
    "    \"learning_rate\": 0.0616974880921061,\n",
    "    \"max_depth\": 344,\n",
    "    \"max_leaves\": 89,\n",
    "    \"min_child_weight\": 10,\n",
    "    \"n_estimators\": 696,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"reg_alpha\": 1.849084818346014,\n",
    "    \"reg_lambda\": 29.680324563362227,\n",
    "    \"subsample\": 0.5902901569391961,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True\n",
    "}\n",
    "\n",
    "hgb_params = {\n",
    "    \"l2_regularization\": 28.13576008319012,\n",
    "    \"learning_rate\": 0.1543598086529694,\n",
    "    \"max_depth\": 325,\n",
    "    \"max_features\": 0.323620656779567,\n",
    "    \"max_iter\": 2490,\n",
    "    \"max_leaf_nodes\": 216,\n",
    "    \"min_samples_leaf\": 12,\n",
    "    \"random_state\": 42,\n",
    "    \"categorical_features\": \"from_dtype\"\n",
    "}\n",
    "\n",
    "lgbm_params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"colsample_bytree\": 0.6467443250209886,\n",
    "    \"learning_rate\": 0.06547186748153115,\n",
    "    \"min_child_samples\": 34,\n",
    "    \"min_child_weight\": 0.24399244943904663,\n",
    "    \"n_estimators\": 498,\n",
    "    \"n_jobs\": -1,\n",
    "    \"num_leaves\": 158,\n",
    "    \"random_state\": 42,\n",
    "    \"reg_alpha\": 6.568921253574134,\n",
    "    \"reg_lambda\": 62.66165355751099,\n",
    "    \"subsample\": 0.0011019938618584968,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "lgbm_goss_params = {\n",
    "    \"boosting_type\": \"goss\",\n",
    "    \"colsample_bytree\": 0.8384834064170148,\n",
    "    \"learning_rate\": 0.07006829797238343,\n",
    "    \"min_child_samples\": 46,\n",
    "    \"min_child_weight\": 0.7625394962666617,\n",
    "    \"n_estimators\": 1887,\n",
    "    \"n_jobs\": -1,\n",
    "    \"num_leaves\": 341,\n",
    "    \"random_state\": 42,\n",
    "    \"reg_alpha\": 10.53082019937197,\n",
    "    \"reg_lambda\": 67.44600065144685,\n",
    "    \"subsample\": 0.4925008305336127,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "lgbm_dart_params = {\n",
    "    \"boosting_type\": \"dart\",\n",
    "    \"colsample_bytree\": 0.7592971191793424,\n",
    "    \"learning_rate\": 0.046141766106846074,\n",
    "    \"min_child_samples\": 18,\n",
    "    \"min_child_weight\": 0.4740109054323218,\n",
    "    \"n_estimators\": 4035,\n",
    "    \"n_jobs\": -1,\n",
    "    \"num_leaves\": 393,\n",
    "    \"random_state\": 42,\n",
    "    \"reg_alpha\": 48.016799341666605,\n",
    "    \"reg_lambda\": 89.12860300833658,\n",
    "    \"subsample\": 0.016333358901112538,\n",
    "    \"verbose\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbc0e2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:03:39.860276Z",
     "iopub.status.busy": "2025-07-10T07:03:39.859979Z",
     "iopub.status.idle": "2025-07-10T07:03:39.864410Z",
     "shell.execute_reply": "2025-07-10T07:03:39.863545Z"
    },
    "papermill": {
     "duration": 0.015488,
     "end_time": "2025-07-10T07:03:39.865921",
     "exception": false,
     "start_time": "2025-07-10T07:03:39.850433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "oof_pred_probs = {}\n",
    "test_pred_probs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eec635",
   "metadata": {
    "papermill": {
     "duration": 0.008464,
     "end_time": "2025-07-10T07:03:39.883459",
     "exception": false,
     "start_time": "2025-07-10T07:03:39.874995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb788d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:03:39.903452Z",
     "iopub.status.busy": "2025-07-10T07:03:39.903145Z",
     "iopub.status.idle": "2025-07-10T07:04:27.845639Z",
     "shell.execute_reply": "2025-07-10T07:04:27.844472Z"
    },
    "papermill": {
     "duration": 47.955123,
     "end_time": "2025-07-10T07:04:27.847283",
     "exception": false,
     "start_time": "2025-07-10T07:03:39.892160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cb_trainer = Trainer(\n",
    "    CatBoostClassifier(**cb_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    use_early_stopping=False,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "# GLOBAL CATBOOST PREPARATION (for use in individual training and ensembles)\n",
    "print(\"Preparing CatBoost-compatible data globally...\")\n",
    "X_cb = X_engineered.copy()\n",
    "X_test_cb = X_test_engineered.copy()\n",
    "\n",
    "# Identify and fix categorical features for CatBoost\n",
    "categorical_features = ['Stage_fear', 'Drained_after_socializing']\n",
    "if 'match_p' in X_cb.columns:\n",
    "    categorical_features.append('match_p')\n",
    "\n",
    "# Convert categorical features to proper format for CatBoost\n",
    "for col in categorical_features:\n",
    "    if col in X_cb.columns:\n",
    "        # Convert to string to avoid CatBoost float categorical error\n",
    "        X_cb[col] = X_cb[col].astype(str)\n",
    "        X_test_cb[col] = X_test_cb[col].astype(str)\n",
    "\n",
    "# Get categorical feature indices\n",
    "cat_features_indices = [X_cb.columns.get_loc(col) for col in categorical_features if col in X_cb.columns]\n",
    "\n",
    "print(f\"Categorical features for CatBoost: {categorical_features}\")\n",
    "print(f\"Categorical feature indices: {cat_features_indices}\")\n",
    "\n",
    "# Update CatBoost parameters to include categorical features (GLOBAL)\n",
    "cb_params_fixed = cb_params.copy()\n",
    "cb_params_fixed['cat_features'] = cat_features_indices\n",
    "\n",
    "print(\"CatBoost-compatible data prepared globally for all models and ensembles!\")\n",
    "\n",
    "# ADDITIONAL: Prepare XGBoost/LightGBM-compatible data (numerical categorical features)\n",
    "print(\"Preparing XGBoost/LightGBM-compatible data...\")\n",
    "X_numeric = X_engineered.copy()\n",
    "X_test_numeric = X_test_engineered.copy()\n",
    "\n",
    "# Ensure categorical features are integers for XGBoost/LightGBM\n",
    "for col in categorical_features:\n",
    "    if col in X_numeric.columns:\n",
    "        X_numeric[col] = X_numeric[col].astype('int32')\n",
    "        X_test_numeric[col] = X_test_numeric[col].astype('int32')\n",
    "\n",
    "print(f\"XGBoost/LightGBM data prepared: {X_numeric.shape}\")\n",
    "print(f\"Data type comparison:\")\n",
    "print(f\"  - CatBoost Stage_fear dtype: {X_cb['Stage_fear'].dtype}\")\n",
    "print(f\"  - XGBoost Stage_fear dtype: {X_numeric['Stage_fear'].dtype}\")\n",
    "\n",
    "# Prepare ensemble-compatible CatBoost parameters (no categorical features specified)\n",
    "cb_params_ensemble = cb_params.copy()\n",
    "cb_params_ensemble.pop('cat_features', None)  # Remove categorical features for ensemble compatibility\n",
    "print(\"Ensemble-compatible CatBoost parameters prepared (no categorical features specified)\")\n",
    "\n",
    "# Use manual CV if Trainer is not available, otherwise use engineered features\n",
    "if Trainer is None:\n",
    "    # Prepare CatBoost-compatible data for manual CV\n",
    "    X_cb_manual = X_engineered.copy()\n",
    "    X_test_cb_manual = X_test_engineered.copy()\n",
    "    \n",
    "    # Fix categorical features\n",
    "    categorical_features = ['Stage_fear', 'Drained_after_socializing']\n",
    "    if 'match_p' in X_cb_manual.columns:\n",
    "        categorical_features.append('match_p')\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        if col in X_cb_manual.columns:\n",
    "            X_cb_manual[col] = X_cb_manual[col].astype(str)\n",
    "            X_test_cb_manual[col] = X_test_cb_manual[col].astype(str)\n",
    "    \n",
    "    cat_features_indices = [X_cb_manual.columns.get_loc(col) for col in categorical_features if col in X_cb_manual.columns]\n",
    "    cb_params_manual = cb_params.copy()\n",
    "    cb_params_manual['cat_features'] = cat_features_indices\n",
    "    \n",
    "    cb_oof, cb_test, cb_scores = manual_cv_train(\n",
    "        CatBoostClassifier(**cb_params_fixed, verbose=False), \n",
    "        X_cb, y, X_test_cb, CFG.cv, \"CatBoost\"\n",
    "    )\n",
    "    scores[\"CatBoost\"] = cb_scores\n",
    "    oof_pred_probs[\"CatBoost\"] = cb_oof\n",
    "    test_pred_probs[\"CatBoost\"] = cb_test\n",
    "else:\n",
    "    # CRITICAL FIX: Prepare data for CatBoost (handle categorical features properly)\n",
    "    print(\"Preparing data for CatBoost...\")\n",
    "    X_cb = X_engineered.copy()\n",
    "    X_test_cb = X_test_engineered.copy()\n",
    "    \n",
    "    # Identify and fix categorical features for CatBoost\n",
    "    categorical_features = ['Stage_fear', 'Drained_after_socializing']\n",
    "    if 'match_p' in X_cb.columns:\n",
    "        categorical_features.append('match_p')\n",
    "    \n",
    "    # Convert categorical features to proper format for CatBoost\n",
    "    for col in categorical_features:\n",
    "        if col in X_cb.columns:\n",
    "            # Convert to string to avoid CatBoost float categorical error\n",
    "            X_cb[col] = X_cb[col].astype(str)\n",
    "            X_test_cb[col] = X_test_cb[col].astype(str)\n",
    "    \n",
    "    # Get categorical feature indices\n",
    "    cat_features_indices = [X_cb.columns.get_loc(col) for col in categorical_features if col in X_cb.columns]\n",
    "    \n",
    "    print(f\"Categorical features for CatBoost: {categorical_features}\")\n",
    "    print(f\"Categorical feature indices: {cat_features_indices}\")\n",
    "    \n",
    "    # Update CatBoost parameters to include categorical features\n",
    "    cb_params_fixed = cb_params.copy()\n",
    "    cb_params_fixed['cat_features'] = cat_features_indices\n",
    "    \n",
    "    # Create new trainer with fixed parameters\n",
    "    cb_trainer_fixed = Trainer(\n",
    "        CatBoostClassifier(**cb_params_fixed),\n",
    "        cv=CFG.cv,\n",
    "        metric=CFG.metric,\n",
    "        use_early_stopping=False,\n",
    "        task=\"binary\",\n",
    "        metric_precision=6,\n",
    "    )\n",
    "    \n",
    "    cb_trainer_fixed.fit(X_cb, y)  # Use properly formatted data\n",
    "    scores[\"CatBoost\"] = cb_trainer_fixed.fold_scores\n",
    "    oof_pred_probs[\"CatBoost\"] = cb_trainer_fixed.oof_preds\n",
    "    test_pred_probs[\"CatBoost\"] = cb_trainer_fixed.predict(X_test_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a8d1ec",
   "metadata": {
    "papermill": {
     "duration": 0.009607,
     "end_time": "2025-07-10T07:04:27.866211",
     "exception": false,
     "start_time": "2025-07-10T07:04:27.856604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f86ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:04:27.885662Z",
     "iopub.status.busy": "2025-07-10T07:04:27.885281Z",
     "iopub.status.idle": "2025-07-10T07:04:30.790157Z",
     "shell.execute_reply": "2025-07-10T07:04:30.788676Z"
    },
    "papermill": {
     "duration": 2.916433,
     "end_time": "2025-07-10T07:04:30.791624",
     "exception": false,
     "start_time": "2025-07-10T07:04:27.875191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_trainer = Trainer(\n",
    "    XGBClassifier(**xgb_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "# Use manual CV if Trainer is not available, otherwise use engineered features\n",
    "if Trainer is None:\n",
    "    xgb_oof, xgb_test, xgb_scores = manual_cv_train(\n",
    "        XGBClassifier(**xgb_params, verbosity=0), \n",
    "        X_engineered, y, X_test_engineered, CFG.cv, \"XGBoost\"\n",
    "    )\n",
    "    scores[\"XGBoost\"] = xgb_scores\n",
    "    oof_pred_probs[\"XGBoost\"] = xgb_oof\n",
    "    test_pred_probs[\"XGBoost\"] = xgb_test\n",
    "else:\n",
    "    xgb_trainer.fit(X_engineered, y)  # FIXED: Use engineered features\n",
    "    scores[\"XGBoost\"] = xgb_trainer.fold_scores\n",
    "    oof_pred_probs[\"XGBoost\"] = xgb_trainer.oof_preds\n",
    "    test_pred_probs[\"XGBoost\"] = xgb_trainer.predict(X_test_engineered)  # FIXED: Use engineered features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b3265",
   "metadata": {
    "papermill": {
     "duration": 0.009572,
     "end_time": "2025-07-10T07:04:30.811377",
     "exception": false,
     "start_time": "2025-07-10T07:04:30.801805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753df84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:04:30.831308Z",
     "iopub.status.busy": "2025-07-10T07:04:30.831014Z",
     "iopub.status.idle": "2025-07-10T07:04:34.869234Z",
     "shell.execute_reply": "2025-07-10T07:04:34.868157Z"
    },
    "papermill": {
     "duration": 4.050074,
     "end_time": "2025-07-10T07:04:34.870889",
     "exception": false,
     "start_time": "2025-07-10T07:04:30.820815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hgb_trainer = Trainer(\n",
    "    HistGradientBoostingClassifier(**hgb_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "hgb_trainer.fit(X, y)\n",
    "\n",
    "scores[\"HistGradientBoosting\"] = hgb_trainer.fold_scores\n",
    "oof_pred_probs[\"HistGradientBoosting\"] = hgb_trainer.oof_preds\n",
    "test_pred_probs[\"HistGradientBoosting\"] = hgb_trainer.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4948b0b1",
   "metadata": {
    "papermill": {
     "duration": 0.009308,
     "end_time": "2025-07-10T07:04:34.890184",
     "exception": false,
     "start_time": "2025-07-10T07:04:34.880876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LightGBM (gbdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3533eebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:04:34.911309Z",
     "iopub.status.busy": "2025-07-10T07:04:34.910993Z",
     "iopub.status.idle": "2025-07-10T07:04:37.959767Z",
     "shell.execute_reply": "2025-07-10T07:04:37.959038Z"
    },
    "papermill": {
     "duration": 3.061585,
     "end_time": "2025-07-10T07:04:37.961263",
     "exception": false,
     "start_time": "2025-07-10T07:04:34.899678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbm_gbdt_trainer = Trainer(\n",
    "    LGBMClassifier(**lgbm_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    use_early_stopping=False,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "lgbm_gbdt_trainer.fit(X, y)\n",
    "\n",
    "scores[\"LightGBM (gbdt)\"] = lgbm_gbdt_trainer.fold_scores\n",
    "oof_pred_probs[\"LightGBM (gbdt)\"] = lgbm_gbdt_trainer.oof_preds\n",
    "test_pred_probs[\"LightGBM (gbdt)\"] = lgbm_gbdt_trainer.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0c9133",
   "metadata": {
    "papermill": {
     "duration": 0.009848,
     "end_time": "2025-07-10T07:04:38.049198",
     "exception": false,
     "start_time": "2025-07-10T07:04:38.039350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LightGBM (goss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565bdbbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:04:38.072345Z",
     "iopub.status.busy": "2025-07-10T07:04:38.072065Z",
     "iopub.status.idle": "2025-07-10T07:04:48.383043Z",
     "shell.execute_reply": "2025-07-10T07:04:48.382123Z"
    },
    "papermill": {
     "duration": 10.324798,
     "end_time": "2025-07-10T07:04:48.384897",
     "exception": false,
     "start_time": "2025-07-10T07:04:38.060099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbm_goss_trainer = Trainer(\n",
    "    LGBMClassifier(**lgbm_goss_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    use_early_stopping=False,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "lgbm_goss_trainer.fit(X, y)\n",
    "\n",
    "scores[\"LightGBM (goss)\"] = lgbm_goss_trainer.fold_scores\n",
    "oof_pred_probs[\"LightGBM (goss)\"] = lgbm_goss_trainer.oof_preds\n",
    "test_pred_probs[\"LightGBM (goss)\"] = lgbm_goss_trainer.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f08cc",
   "metadata": {
    "papermill": {
     "duration": 0.010248,
     "end_time": "2025-07-10T07:04:48.406164",
     "exception": false,
     "start_time": "2025-07-10T07:04:48.395916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LightGBM (dart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2cf0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:04:48.430082Z",
     "iopub.status.busy": "2025-07-10T07:04:48.429328Z",
     "iopub.status.idle": "2025-07-10T07:10:07.201072Z",
     "shell.execute_reply": "2025-07-10T07:10:07.197872Z"
    },
    "papermill": {
     "duration": 318.786852,
     "end_time": "2025-07-10T07:10:07.204034",
     "exception": false,
     "start_time": "2025-07-10T07:04:48.417182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbm_dart_trainer = Trainer(\n",
    "    LGBMClassifier(**lgbm_dart_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    use_early_stopping=False,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "lgbm_dart_trainer.fit(X, y)\n",
    "\n",
    "scores[\"LightGBM (dart)\"] = lgbm_dart_trainer.fold_scores\n",
    "oof_pred_probs[\"LightGBM (dart)\"] = lgbm_dart_trainer.oof_preds\n",
    "test_pred_probs[\"LightGBM (dart)\"] = lgbm_dart_trainer.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "additional_models",
   "metadata": {},
   "source": [
    "# Additional Models for Ensemble Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random_forest_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features': 'sqrt',\n",
    "    'bootstrap': True,\n",
    "    'random_state': CFG.seed,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "rf_trainer = Trainer(\n",
    "    RandomForestClassifier(**rf_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "# Use manual CV if Trainer is not available\n",
    "if Trainer is None:\n",
    "    rf_oof, rf_test, rf_scores = manual_cv_train(\n",
    "        RandomForestClassifier(**rf_params), \n",
    "        X_engineered, y, X_test_engineered, CFG.cv, \"RandomForest\"\n",
    "    )\n",
    "    scores[\"RandomForest\"] = rf_scores\n",
    "    oof_pred_probs[\"RandomForest\"] = rf_oof\n",
    "    test_pred_probs[\"RandomForest\"] = rf_test\n",
    "else:\n",
    "    rf_trainer.fit(X_engineered, y)\n",
    "    scores[\"RandomForest\"] = rf_trainer.fold_scores\n",
    "    oof_pred_probs[\"RandomForest\"] = rf_trainer.oof_preds\n",
    "    test_pred_probs[\"RandomForest\"] = rf_trainer.predict(X_test_engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra_trees_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Trees\n",
    "et_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_split': 3,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'sqrt',\n",
    "    'bootstrap': False,\n",
    "    'random_state': CFG.seed,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "et_trainer = Trainer(\n",
    "    ExtraTreesClassifier(**et_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "et_trainer.fit(X_engineered, y)\n",
    "\n",
    "scores[\"ExtraTrees\"] = et_trainer.fold_scores\n",
    "oof_pred_probs[\"ExtraTrees\"] = et_trainer.oof_preds\n",
    "test_pred_probs[\"ExtraTrees\"] = et_trainer.predict(X_test_engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural_network_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network (MLP)\n",
    "# Scale features for neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_engineered)\n",
    "X_test_scaled = scaler.transform(X_test_engineered)\n",
    "\n",
    "# Convert back to DataFrame to preserve column indexing\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X_engineered.columns, index=X_engineered.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_engineered.columns, index=X_test_engineered.index)\n",
    "\n",
    "mlp_params = {\n",
    "    'hidden_layer_sizes': (100, 50, 25),\n",
    "    'activation': 'relu',\n",
    "    'solver': 'adam',\n",
    "    'alpha': 0.001,\n",
    "    'learning_rate': 'adaptive',\n",
    "    'max_iter': 1000,\n",
    "    'random_state': CFG.seed,\n",
    "    'early_stopping': True,\n",
    "    'validation_fraction': 0.1\n",
    "}\n",
    "\n",
    "mlp_trainer = Trainer(\n",
    "    MLPClassifier(**mlp_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "mlp_trainer.fit(X_scaled, y)\n",
    "\n",
    "scores[\"NeuralNetwork\"] = mlp_trainer.fold_scores\n",
    "oof_pred_probs[\"NeuralNetwork\"] = mlp_trainer.oof_preds\n",
    "test_pred_probs[\"NeuralNetwork\"] = mlp_trainer.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "additional_diverse_models",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING ADDITIONAL DIVERSE MODELS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# AdaBoost Classifier\n",
    "print(\"\\nTraining AdaBoost...\")\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_params = {\n",
    "    'n_estimators': 200,\n",
    "    'learning_rate': 0.8,\n",
    "    'algorithm': 'SAMME.R',\n",
    "    'random_state': CFG.seed\n",
    "}\n",
    "\n",
    "ada_trainer = Trainer(\n",
    "    AdaBoostClassifier(**ada_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    use_early_stopping=False,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "ada_trainer.fit(X_engineered, y)\n",
    "\n",
    "scores[\"AdaBoost\"] = ada_trainer.fold_scores\n",
    "oof_pred_probs[\"AdaBoost\"] = ada_trainer.oof_preds\n",
    "test_pred_probs[\"AdaBoost\"] = ada_trainer.predict(X_test_engineered)\n",
    "\n",
    "print(f\"AdaBoost CV Score: {np.mean(ada_trainer.fold_scores):.6f} ± {np.std(ada_trainer.fold_scores):.6f}\")\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "print(\"\\nTraining Gradient Boosting...\")\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': 200,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'subsample': 0.8,\n",
    "    'random_state': CFG.seed\n",
    "}\n",
    "\n",
    "gb_trainer = Trainer(\n",
    "    GradientBoostingClassifier(**gb_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    use_early_stopping=False,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "gb_trainer.fit(X_engineered, y)\n",
    "\n",
    "scores[\"GradientBoosting\"] = gb_trainer.fold_scores\n",
    "oof_pred_probs[\"GradientBoosting\"] = gb_trainer.oof_preds\n",
    "test_pred_probs[\"GradientBoosting\"] = gb_trainer.predict(X_test_engineered)\n",
    "\n",
    "print(f\"Gradient Boosting CV Score: {np.mean(gb_trainer.fold_scores):.6f} ± {np.std(gb_trainer.fold_scores):.6f}\")\n",
    "\n",
    "# Naive Bayes (for diversity)\n",
    "print(\"\\nTraining Naive Bayes...\")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_trainer = Trainer(\n",
    "    GaussianNB(),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    use_early_stopping=False,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    ")\n",
    "\n",
    "nb_trainer.fit(X_scaled, y)  # Use scaled features for Naive Bayes\n",
    "\n",
    "scores[\"NaiveBayes\"] = nb_trainer.fold_scores\n",
    "oof_pred_probs[\"NaiveBayes\"] = nb_trainer.oof_preds\n",
    "test_pred_probs[\"NaiveBayes\"] = nb_trainer.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Naive Bayes CV Score: {np.mean(nb_trainer.fold_scores):.6f} ± {np.std(nb_trainer.fold_scores):.6f}\")\n",
    "\n",
    "print(\"\\nAdditional diverse models training completed!\")\n",
    "print(f\"Total models trained: {len(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ef90e",
   "metadata": {
    "papermill": {
     "duration": 0.011746,
     "end_time": "2025-07-10T07:10:07.234637",
     "exception": false,
     "start_time": "2025-07-10T07:10:07.222891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b1cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:10:07.260019Z",
     "iopub.status.busy": "2025-07-10T07:10:07.259691Z",
     "iopub.status.idle": "2025-07-10T07:10:07.325940Z",
     "shell.execute_reply": "2025-07-10T07:10:07.324861Z"
    },
    "papermill": {
     "duration": 0.08173,
     "end_time": "2025-07-10T07:10:07.327656",
     "exception": false,
     "start_time": "2025-07-10T07:10:07.245926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_pred_probs_files = glob.glob(f'/kaggle/input/s05e07-personality-type-prediction-autogluon/*_oof_pred_probs_*.pkl')\n",
    "test_pred_probs_files = glob.glob(f'/kaggle/input/s05e07-personality-type-prediction-autogluon/*_test_pred_probs_*.pkl')\n",
    "\n",
    "ag_oof_pred_probs = joblib.load(oof_pred_probs_files[0])\n",
    "ag_test_pred_probs = joblib.load(test_pred_probs_files[0])\n",
    "\n",
    "ag_scores = []\n",
    "for _, val_idx in CFG.cv.split(X, y):\n",
    "    y_val = y[val_idx]\n",
    "    y_preds = ag_oof_pred_probs[val_idx]\n",
    "    score = accuracy_score(y_val, y_preds >= 0.5)\n",
    "    ag_scores.append(score)\n",
    "    \n",
    "oof_pred_probs[\"AutoGluon\"], test_pred_probs[\"AutoGluon\"], scores[\"AutoGluon\"] = ag_oof_pred_probs, ag_test_pred_probs, ag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310ac53",
   "metadata": {
    "papermill": {
     "duration": 0.011731,
     "end_time": "2025-07-10T07:10:07.351394",
     "exception": false,
     "start_time": "2025-07-10T07:10:07.339663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe3f2b2",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-07-10T07:10:07.374845Z",
     "iopub.status.busy": "2025-07-10T07:10:07.374542Z",
     "iopub.status.idle": "2025-07-10T07:10:07.382690Z",
     "shell.execute_reply": "2025-07-10T07:10:07.381593Z"
    },
    "papermill": {
     "duration": 0.021918,
     "end_time": "2025-07-10T07:10:07.384597",
     "exception": false,
     "start_time": "2025-07-10T07:10:07.362679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_weights(weights, title):\n",
    "    sorted_indices = np.argsort(weights[0])[::-1]\n",
    "    sorted_coeffs = np.array(weights[0])[sorted_indices]\n",
    "    sorted_model_names = np.array(list(oof_pred_probs.keys()))[sorted_indices]\n",
    "\n",
    "    plt.figure(figsize=(10, weights.shape[1] * 0.4))\n",
    "    ax = sns.barplot(x=sorted_coeffs, y=sorted_model_names, palette=\"RdYlGn_r\")\n",
    "\n",
    "    for i, (value, name) in enumerate(zip(sorted_coeffs, sorted_model_names)):\n",
    "        if value >= 0:\n",
    "            ax.text(value, i, f'{value:.3f}', va='center', ha='left', color='black')\n",
    "        else:\n",
    "            ax.text(value, i, f'{value:.3f}', va='center', ha='right', color='black')\n",
    "\n",
    "    xlim = ax.get_xlim()\n",
    "    ax.set_xlim(xlim[0] - 0.1 * abs(xlim[0]), xlim[1] + 0.1 * abs(xlim[1]))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c284878",
   "metadata": {
    "papermill": {
     "duration": 0.010747,
     "end_time": "2025-07-10T07:10:07.406929",
     "exception": false,
     "start_time": "2025-07-10T07:10:07.396182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078c9c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:10:07.432715Z",
     "iopub.status.busy": "2025-07-10T07:10:07.431995Z",
     "iopub.status.idle": "2025-07-10T07:10:07.457360Z",
     "shell.execute_reply": "2025-07-10T07:10:07.455678Z"
    },
    "papermill": {
     "duration": 0.041049,
     "end_time": "2025-07-10T07:10:07.459572",
     "exception": false,
     "start_time": "2025-07-10T07:10:07.418523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = logit(pd.DataFrame(oof_pred_probs).clip(1e-15, 1-1e-15))\n",
    "X_test = logit(pd.DataFrame(test_pred_probs).clip(1e-15, 1-1e-15))\n",
    "\n",
    "joblib.dump(oof_pred_probs, \"oof_pred_probs.pkl\")\n",
    "joblib.dump(test_pred_probs, \"test_pred_probs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3df38",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-07-10T07:10:07.486110Z",
     "iopub.status.busy": "2025-07-10T07:10:07.485756Z",
     "iopub.status.idle": "2025-07-10T07:18:43.254156Z",
     "shell.execute_reply": "2025-07-10T07:18:43.253060Z"
    },
    "papermill": {
     "duration": 515.783466,
     "end_time": "2025-07-10T07:18:43.256002",
     "exception": false,
     "start_time": "2025-07-10T07:10:07.472536",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    solver_penalty_options = [\n",
    "        ('liblinear', 'l1'),\n",
    "        ('liblinear', 'l2'),\n",
    "        ('lbfgs', 'l2'),\n",
    "        ('lbfgs', None),\n",
    "        ('newton-cg', 'l2'),\n",
    "        ('newton-cg', None),\n",
    "        ('newton-cholesky', 'l2'),\n",
    "        ('newton-cholesky', None)\n",
    "    ]\n",
    "    solver, penalty = trial.suggest_categorical('solver_penalty', solver_penalty_options)\n",
    "    \n",
    "    params = {\n",
    "        'random_state': CFG.seed,\n",
    "        'max_iter': 1000,\n",
    "        'C': trial.suggest_float('C', 0, 1),\n",
    "        'tol': trial.suggest_float('tol', 1e-6, 1e-2),\n",
    "        'fit_intercept': trial.suggest_categorical('fit_intercept', [True, False]),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        'solver': solver,\n",
    "        'penalty': penalty\n",
    "    }\n",
    "    \n",
    "    threshold = trial.suggest_float('threshold', 0, 1)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        LogisticRegression(**params),\n",
    "        cv=CFG.cv,\n",
    "        metric=CFG.metric,\n",
    "        metric_precision=6,\n",
    "        metric_threshold=threshold,\n",
    "        use_early_stopping=False,\n",
    "        verbose=False,\n",
    "        task=\"binary\",\n",
    "    )\n",
    "    trainer.fit(X, y)\n",
    "    \n",
    "    return np.mean(trainer.fold_scores)\n",
    "\n",
    "# Enhanced hyperparameter optimization\n",
    "sampler = optuna.samplers.TPESampler(\n",
    "    seed=CFG.seed, \n",
    "    multivariate=True, \n",
    "    n_startup_trials=CFG.n_startup_trials,\n",
    "    n_ei_candidates=24,\n",
    "    gamma=lambda x: min(int(0.25 * x), 25)\n",
    ")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='maximize', \n",
    "    sampler=sampler,\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=5)\n",
    ")\n",
    "\n",
    "print(f\"Starting hyperparameter optimization with {CFG.n_optuna_trials} trials...\")\n",
    "study.optimize(objective, n_trials=CFG.n_optuna_trials, n_jobs=-1, show_progress_bar=True)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best score: {study.best_value:.6f}\")\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7fe377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:18:43.330403Z",
     "iopub.status.busy": "2025-07-10T07:18:43.330062Z",
     "iopub.status.idle": "2025-07-10T07:18:43.335969Z",
     "shell.execute_reply": "2025-07-10T07:18:43.334969Z"
    },
    "papermill": {
     "duration": 0.045803,
     "end_time": "2025-07-10T07:18:43.337613",
     "exception": false,
     "start_time": "2025-07-10T07:18:43.291810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "solver, penalty = best_params['solver_penalty']\n",
    "lr_params = {\n",
    "    'random_state': CFG.seed,\n",
    "    'max_iter': 1000,\n",
    "    'C': best_params['C'],\n",
    "    'tol': best_params['tol'],\n",
    "    'fit_intercept': best_params['fit_intercept'],\n",
    "    'class_weight': best_params['class_weight'],\n",
    "    'solver': solver,\n",
    "    'penalty': penalty\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5bf16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:18:43.415162Z",
     "iopub.status.busy": "2025-07-10T07:18:43.414423Z",
     "iopub.status.idle": "2025-07-10T07:18:43.419746Z",
     "shell.execute_reply": "2025-07-10T07:18:43.418817Z"
    },
    "papermill": {
     "duration": 0.046063,
     "end_time": "2025-07-10T07:18:43.421303",
     "exception": false,
     "start_time": "2025-07-10T07:18:43.375240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(json.dumps(lr_params, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a6d22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:18:43.497395Z",
     "iopub.status.busy": "2025-07-10T07:18:43.497088Z",
     "iopub.status.idle": "2025-07-10T07:18:43.502111Z",
     "shell.execute_reply": "2025-07-10T07:18:43.501071Z"
    },
    "papermill": {
     "duration": 0.044607,
     "end_time": "2025-07-10T07:18:43.503746",
     "exception": false,
     "start_time": "2025-07-10T07:18:43.459139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_threshold = study.best_params['threshold']\n",
    "print(f'Best threshold: {best_threshold:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff1c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:18:43.578917Z",
     "iopub.status.busy": "2025-07-10T07:18:43.578583Z",
     "iopub.status.idle": "2025-07-10T07:18:44.775344Z",
     "shell.execute_reply": "2025-07-10T07:18:44.774015Z"
    },
    "papermill": {
     "duration": 1.23675,
     "end_time": "2025-07-10T07:18:44.777009",
     "exception": false,
     "start_time": "2025-07-10T07:18:43.540259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_trainer = Trainer(\n",
    "    LogisticRegression(**lr_params),\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    metric_threshold=best_threshold,\n",
    "    metric_precision=6,\n",
    "    use_early_stopping=False,\n",
    "    task=\"binary\",\n",
    ")\n",
    "\n",
    "lr_trainer.fit(X, y)\n",
    "\n",
    "scores[\"LogisticRegression\"] = lr_trainer.fold_scores\n",
    "lr_test_pred_probs = lr_trainer.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15898a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:18:44.853229Z",
     "iopub.status.busy": "2025-07-10T07:18:44.852868Z",
     "iopub.status.idle": "2025-07-10T07:18:44.904141Z",
     "shell.execute_reply": "2025-07-10T07:18:44.903184Z"
    },
    "papermill": {
     "duration": 0.090277,
     "end_time": "2025-07-10T07:18:44.905804",
     "exception": false,
     "start_time": "2025-07-10T07:18:44.815527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_submission('logistic-regression', _X_test, lr_test_pred_probs, np.mean(scores['LogisticRegression']), best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e7fa85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:18:44.979557Z",
     "iopub.status.busy": "2025-07-10T07:18:44.979211Z",
     "iopub.status.idle": "2025-07-10T07:18:44.984649Z",
     "shell.execute_reply": "2025-07-10T07:18:44.983566Z"
    },
    "papermill": {
     "duration": 0.043882,
     "end_time": "2025-07-10T07:18:44.986265",
     "exception": false,
     "start_time": "2025-07-10T07:18:44.942383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_coeffs = np.zeros((1,len(X.columns)))\n",
    "for estimator in lr_trainer.estimators:\n",
    "    lr_coeffs += estimator.coef_ / CFG.n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1bade8",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2025-07-10T07:18:45.061575Z",
     "iopub.status.busy": "2025-07-10T07:18:45.061222Z",
     "iopub.status.idle": "2025-07-10T07:18:45.371791Z",
     "shell.execute_reply": "2025-07-10T07:18:45.370400Z"
    },
    "papermill": {
     "duration": 0.350086,
     "end_time": "2025-07-10T07:18:45.373747",
     "exception": false,
     "start_time": "2025-07-10T07:18:45.023661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_weights(lr_coeffs, 'LR Coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48c6fa3",
   "metadata": {
    "papermill": {
     "duration": 0.036874,
     "end_time": "2025-07-10T07:18:45.448464",
     "exception": false,
     "start_time": "2025-07-10T07:18:45.411590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Advanced Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced_ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression as LR_Meta\n",
    "\n",
    "# Create stacking ensemble if enabled\n",
    "if CFG.use_stacking:\n",
    "    print(\"Creating Stacking Ensemble...\")\n",
    "    \n",
    "    # Define base estimators for stacking (use numerical data for compatibility)\n",
    "    # Note: Using cb_params_ensemble (defined globally) for ensemble compatibility\n",
    "    base_estimators = [\n",
    "        ('catboost', CatBoostClassifier(**cb_params_ensemble)),\n",
    "        ('xgboost', XGBClassifier(**xgb_params)),\n",
    "        ('lightgbm', LGBMClassifier(**lgbm_params)),\n",
    "        ('histgb', HistGradientBoostingClassifier(**hgb_params))\n",
    "    ]\n",
    "    \n",
    "    # Create stacking classifier\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=LR_Meta(random_state=CFG.seed, max_iter=1000),\n",
    "        cv=CFG.cv,\n",
    "        stack_method='predict_proba',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Train stacking ensemble\n",
    "    stacking_trainer = Trainer(\n",
    "        stacking_clf,\n",
    "        cv=CFG.cv,\n",
    "        metric=CFG.metric,\n",
    "        task=\"binary\",\n",
    "        metric_precision=6,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    stacking_trainer.fit(X_numeric, y)  # Use numerical data for ensemble compatibility\n",
    "    \n",
    "    scores[\"StackingEnsemble\"] = stacking_trainer.fold_scores\n",
    "    oof_pred_probs[\"StackingEnsemble\"] = stacking_trainer.oof_preds\n",
    "    test_pred_probs[\"StackingEnsemble\"] = stacking_trainer.predict(X_test_numeric)  # Use numerical data for ensemble compatibility\n",
    "    \n",
    "    print(f\"Stacking Ensemble CV Score: {np.mean(stacking_trainer.fold_scores):.6f} ± {np.std(stacking_trainer.fold_scores):.6f}\")\n",
    "\n",
    "# Create voting ensemble\n",
    "print(\"\\nCreating Voting Ensemble...\")\n",
    "voting_estimators = [\n",
    "    ('catboost', CatBoostClassifier(**cb_params_ensemble)),\n",
    "    ('xgboost', XGBClassifier(**xgb_params)),\n",
    "    ('lightgbm', LGBMClassifier(**lgbm_params)),\n",
    "    ('histgb', HistGradientBoostingClassifier(**hgb_params))\n",
    "]\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=voting_estimators,\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "voting_trainer = Trainer(\n",
    "    voting_clf,\n",
    "    cv=CFG.cv,\n",
    "    metric=CFG.metric,\n",
    "    task=\"binary\",\n",
    "    metric_precision=6,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "voting_trainer.fit(X_numeric, y)  # Use numerical data for ensemble compatibility\n",
    "\n",
    "scores[\"VotingEnsemble\"] = voting_trainer.fold_scores\n",
    "oof_pred_probs[\"VotingEnsemble\"] = voting_trainer.oof_preds\n",
    "test_pred_probs[\"VotingEnsemble\"] = voting_trainer.predict(X_test_numeric)  # Use numerical data for ensemble compatibility\n",
    "\n",
    "print(f\"Voting Ensemble CV Score: {np.mean(voting_trainer.fold_scores):.6f} ± {np.std(voting_trainer.fold_scores):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted_average_section",
   "metadata": {},
   "source": [
    "## Weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202c576",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-07-10T07:18:45.522852Z",
     "iopub.status.busy": "2025-07-10T07:18:45.522469Z",
     "iopub.status.idle": "2025-07-10T07:19:11.999060Z",
     "shell.execute_reply": "2025-07-10T07:19:11.997878Z"
    },
    "papermill": {
     "duration": 26.515898,
     "end_time": "2025-07-10T07:19:12.000722",
     "exception": false,
     "start_time": "2025-07-10T07:18:45.484824",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    weights = np.array([trial.suggest_float(m, -1, 1) for m in oof_pred_probs.keys()])\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    preds = np.zeros(len(y))\n",
    "    for m, weight in zip(oof_pred_probs.keys(), weights):\n",
    "        preds += oof_pred_probs[m] * weight\n",
    "        \n",
    "    threshold = trial.suggest_float('threshold', 0, 1)\n",
    "            \n",
    "    return accuracy_score(y, (preds > threshold).astype(int))\n",
    "\n",
    "# Enhanced ensemble weights optimization\n",
    "sampler = optuna.samplers.TPESampler(\n",
    "    seed=CFG.seed, \n",
    "    multivariate=True, \n",
    "    n_startup_trials=CFG.n_startup_trials,\n",
    "    n_ei_candidates=24\n",
    ")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='maximize', \n",
    "    sampler=sampler,\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=3)\n",
    ")\n",
    "\n",
    "print(f\"Optimizing ensemble weights with {CFG.n_optuna_trials} trials...\")\n",
    "study.optimize(objective, n_trials=CFG.n_optuna_trials, n_jobs=-1, show_progress_bar=True)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f\"Best ensemble score: {study.best_value:.6f}\")\n",
    "print(f\"Optimal weights: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2ea97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:19:12.132435Z",
     "iopub.status.busy": "2025-07-10T07:19:12.132102Z",
     "iopub.status.idle": "2025-07-10T07:19:12.137252Z",
     "shell.execute_reply": "2025-07-10T07:19:12.136356Z"
    },
    "papermill": {
     "duration": 0.071602,
     "end_time": "2025-07-10T07:19:12.138927",
     "exception": false,
     "start_time": "2025-07-10T07:19:12.067325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores['WeightedAverage'] = [study.best_value] * CFG.n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec21ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:19:12.270471Z",
     "iopub.status.busy": "2025-07-10T07:19:12.270167Z",
     "iopub.status.idle": "2025-07-10T07:19:12.278092Z",
     "shell.execute_reply": "2025-07-10T07:19:12.276792Z"
    },
    "papermill": {
     "duration": 0.076316,
     "end_time": "2025-07-10T07:19:12.279592",
     "exception": false,
     "start_time": "2025-07-10T07:19:12.203276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_weights = np.array([study.best_params[m] for m in oof_pred_probs.keys()])\n",
    "best_weights /= np.sum(best_weights)\n",
    "\n",
    "best_weights = {\n",
    "    model: weight for model, weight in sorted(\n",
    "        zip(oof_pred_probs.keys(), best_weights),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "}\n",
    "print(json.dumps(best_weights, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cfd68f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:19:12.406791Z",
     "iopub.status.busy": "2025-07-10T07:19:12.406448Z",
     "iopub.status.idle": "2025-07-10T07:19:12.411968Z",
     "shell.execute_reply": "2025-07-10T07:19:12.410747Z"
    },
    "papermill": {
     "duration": 0.0706,
     "end_time": "2025-07-10T07:19:12.413435",
     "exception": false,
     "start_time": "2025-07-10T07:19:12.342835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_threshold = study.best_params['threshold']\n",
    "print(f'Best threshold: {best_threshold:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d91dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:19:12.541410Z",
     "iopub.status.busy": "2025-07-10T07:19:12.541131Z",
     "iopub.status.idle": "2025-07-10T07:19:12.546379Z",
     "shell.execute_reply": "2025-07-10T07:19:12.545606Z"
    },
    "papermill": {
     "duration": 0.070194,
     "end_time": "2025-07-10T07:19:12.547953",
     "exception": false,
     "start_time": "2025-07-10T07:19:12.477759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weighted_test_preds = np.zeros(len(test_pred_probs[\"CatBoost\"]))\n",
    "for m, weight in best_weights.items():\n",
    "    weighted_test_preds += test_pred_probs[m] * weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b87a9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:19:12.676011Z",
     "iopub.status.busy": "2025-07-10T07:19:12.675354Z",
     "iopub.status.idle": "2025-07-10T07:19:12.698604Z",
     "shell.execute_reply": "2025-07-10T07:19:12.697710Z"
    },
    "papermill": {
     "duration": 0.090837,
     "end_time": "2025-07-10T07:19:12.700550",
     "exception": false,
     "start_time": "2025-07-10T07:19:12.609713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_submission('weighted-ensemble', _X_test, weighted_test_preds, np.mean(scores['WeightedAverage']), best_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced_ensemble",
   "metadata": {},
   "source": [
    "# 🚀 Enhanced Ensemble with Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimized_ensemble_creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING OPTIMIZED ENSEMBLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Optimize ensemble weights\n",
    "if len(oof_pred_probs) >= 2:\n",
    "    print(\"\\n1. OPTIMIZING ENSEMBLE WEIGHTS...\")\n",
    "    optimal_weights = optimize_ensemble_weights(oof_pred_probs, y)\n",
    "    \n",
    "    # Create optimized ensemble OOF predictions\n",
    "    optimized_oof = np.zeros(len(y))\n",
    "    for i, (model_name, oof_pred) in enumerate(oof_pred_probs.items()):\n",
    "        optimized_oof += optimal_weights[i] * oof_pred\n",
    "    \n",
    "    # Create optimized ensemble test predictions\n",
    "    optimized_test = np.zeros(len(X_test_engineered))\n",
    "    for i, (model_name, test_pred) in enumerate(test_pred_probs.items()):\n",
    "        optimized_test += optimal_weights[i] * test_pred\n",
    "    \n",
    "    # 2. Find optimal threshold\n",
    "    print(\"\\n2. OPTIMIZING DECISION THRESHOLD...\")\n",
    "    optimal_threshold = find_optimal_threshold(optimized_oof, y)\n",
    "    \n",
    "    # Calculate optimized ensemble score\n",
    "    optimized_score = accuracy_score(y, (optimized_oof > optimal_threshold).astype(int))\n",
    "    \n",
    "    print(f\"\\n=== OPTIMIZED ENSEMBLE RESULTS ===\")\n",
    "    print(f\"Optimized Ensemble Score: {optimized_score:.6f}\")\n",
    "    print(f\"Optimal Threshold: {optimal_threshold:.3f}\")\n",
    "    \n",
    "    # Compare with simple average\n",
    "    simple_avg = np.mean(list(oof_pred_probs.values()), axis=0)\n",
    "    simple_score = accuracy_score(y, (simple_avg > 0.5).astype(int))\n",
    "    improvement = optimized_score - simple_score\n",
    "    \n",
    "    print(f\"\\nSimple Average Score: {simple_score:.6f}\")\n",
    "    print(f\"Improvement: +{improvement:.6f} ({improvement/simple_score*100:.2f}%)\")\n",
    "    \n",
    "    # Save optimized ensemble submission\n",
    "    save_submission('OptimizedEnsemble', X_test, optimized_test, optimized_score, optimal_threshold)\n",
    "    \n",
    "    # Store results\n",
    "    scores['OptimizedEnsemble'] = [optimized_score] * CFG.n_folds\n",
    "    oof_pred_probs['OptimizedEnsemble'] = optimized_oof\n",
    "    test_pred_probs['OptimizedEnsemble'] = optimized_test\n",
    "    \n",
    "else:\n",
    "    print(\"Not enough models for ensemble optimization\")\n",
    "\n",
    "print(\"\\nOptimized ensemble creation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level2_stacking",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING LEVEL 2 STACKED ENSEMBLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(oof_pred_probs) >= 3:\n",
    "    # Create Level 2 features from Level 1 predictions\n",
    "    level2_features = pd.DataFrame(oof_pred_probs)\n",
    "    \n",
    "    # Add selected original features (most important ones)\n",
    "    important_features = ['Social_event_attendance', 'Time_spent_Alone', 'Stage_fear', \n",
    "                         'Drained_after_socializing', 'Friends_circle_size']\n",
    "    \n",
    "    for feat in important_features:\n",
    "        if feat in X_engineered.columns:\n",
    "            level2_features[feat] = X_engineered[feat]\n",
    "    \n",
    "    print(f\"Level 2 features shape: {level2_features.shape}\")\n",
    "    print(f\"Level 2 features: {list(level2_features.columns)}\")\n",
    "    \n",
    "    # Handle missing values in training features\n",
    "    print(f\"Checking for NaN values in Level 2 training features...\")\n",
    "    nan_count = level2_features.isnull().sum().sum()\n",
    "    if nan_count > 0:\n",
    "        print(f\"Found {nan_count} NaN values, filling with median...\")\n",
    "        # Use pandas fillna to avoid shape issues\n",
    "        for col in level2_features.columns:\n",
    "            if level2_features[col].isnull().sum() > 0:\n",
    "                if level2_features[col].dtype in ['float64', 'int64']:\n",
    "                    median_val = level2_features[col].median()\n",
    "                    if pd.isna(median_val):\n",
    "                        median_val = 0.5\n",
    "                    level2_features[col] = level2_features[col].fillna(median_val)\n",
    "                else:\n",
    "                    level2_features[col] = level2_features[col].fillna(0.5)\n",
    "        \n",
    "        print(f\"NaN values after cleaning: {level2_features.isnull().sum().sum()}\")\n",
    "    else:\n",
    "        print(\"No NaN values found in Level 2 training features\")\n",
    "    \n",
    "    # Train Level 2 model with cross-validation\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    level2_oof = np.zeros(len(y))\n",
    "    level2_models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(CFG.cv.split(level2_features, y)):\n",
    "        X_train_l2 = level2_features.iloc[train_idx]\n",
    "        y_train_l2 = y.iloc[train_idx]\n",
    "        X_val_l2 = level2_features.iloc[val_idx]\n",
    "        \n",
    "        # Train Level 2 model\n",
    "        level2_model = LogisticRegression(random_state=CFG.seed, max_iter=1000)\n",
    "        level2_model.fit(X_train_l2, y_train_l2)\n",
    "        \n",
    "        # Predict validation\n",
    "        val_preds = level2_model.predict_proba(X_val_l2)[:, 1]\n",
    "        level2_oof[val_idx] = val_preds\n",
    "        \n",
    "        level2_models.append(level2_model)\n",
    "    \n",
    "    # Level 2 test predictions\n",
    "    level2_test_features = pd.DataFrame(test_pred_probs)\n",
    "    for feat in important_features:\n",
    "        if feat in X_test_engineered.columns:\n",
    "            level2_test_features[feat] = X_test_engineered[feat]\n",
    "    \n",
    "    # Handle missing values in test features\n",
    "    print(f\"Checking for NaN values in Level 2 test features...\")\n",
    "    nan_count = level2_test_features.isnull().sum().sum()\n",
    "    if nan_count > 0:\n",
    "        print(f\"Found {nan_count} NaN values, filling with median...\")\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        # Use pandas fillna instead of sklearn imputer to avoid shape issues\n",
    "        level2_test_features_clean = level2_test_features.copy()\n",
    "        \n",
    "        # Fill NaN values with median for numeric columns, 0.5 for others\n",
    "        for col in level2_test_features.columns:\n",
    "            if level2_test_features[col].isnull().sum() > 0:\n",
    "                if level2_test_features[col].dtype in ['float64', 'int64']:\n",
    "                    median_val = level2_test_features[col].median()\n",
    "                    if pd.isna(median_val):  # If all values are NaN\n",
    "                        median_val = 0.5  # Default for probability-like features\n",
    "                    level2_test_features_clean[col] = level2_test_features[col].fillna(median_val)\n",
    "                else:\n",
    "                    level2_test_features_clean[col] = level2_test_features[col].fillna(0.5)\n",
    "        \n",
    "        print(f\"NaN values after cleaning: {level2_test_features_clean.isnull().sum().sum()}\")\n",
    "    else:\n",
    "        print(\"No NaN values found in Level 2 test features\")\n",
    "        level2_test_features_clean = level2_test_features\n",
    "    \n",
    "    level2_test_preds = np.zeros(len(X_test_engineered))\n",
    "    for model in level2_models:\n",
    "        level2_test_preds += model.predict_proba(level2_test_features_clean)[:, 1] / len(level2_models)\n",
    "    \n",
    "    # Calculate Level 2 score\n",
    "    level2_score = accuracy_score(y, (level2_oof > 0.5).astype(int))\n",
    "    \n",
    "    print(f\"\\n=== LEVEL 2 STACKING RESULTS ===\")\n",
    "    print(f\"Level 2 Stacking Score: {level2_score:.6f}\")\n",
    "    \n",
    "    # Save Level 2 submission\n",
    "    save_submission('Level2Stacking', X_test, level2_test_preds, level2_score)\n",
    "    \n",
    "    # Store results\n",
    "    scores['Level2Stacking'] = [level2_score] * CFG.n_folds\n",
    "    oof_pred_probs['Level2Stacking'] = level2_oof\n",
    "    test_pred_probs['Level2Stacking'] = level2_test_preds\n",
    "    \n",
    "else:\n",
    "    print(\"Not enough models for Level 2 stacking\")\n",
    "\n",
    "print(\"\\nLevel 2 stacking completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_interpretation",
   "metadata": {},
   "source": [
    "# Model Interpretation and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importance_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis from tree-based models\n",
    "print(\"=== FEATURE IMPORTANCE ANALYSIS ===\")\n",
    "\n",
    "# Get feature importance from CatBoost (usually most reliable)\n",
    "if 'CatBoost' in scores:\n",
    "    # Check if we have a CatBoost trainer available\n",
    "    if 'cb_trainer_fixed' in locals():\n",
    "        cb_model = cb_trainer_fixed.estimators[0]  # Get first fold model from fixed trainer\n",
    "        feature_names = X_cb.columns  # Use CatBoost-compatible feature names\n",
    "    elif 'cb_trainer' in locals():\n",
    "        cb_model = cb_trainer.estimators[0]  # Get first fold model from original trainer\n",
    "        feature_names = X_engineered.columns\n",
    "    else:\n",
    "        print(\"No CatBoost trainer available for feature importance\")\n",
    "        cb_model = None\n",
    "    \n",
    "    if cb_model is not None:\n",
    "        try:\n",
    "            importance_scores = cb_model.feature_importances_\n",
    "    \n",
    "    # Create feature importance dataframe\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importance_scores\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 15 Most Important Features (CatBoost):\")\n",
    "    for i, (_, row) in enumerate(feature_importance_df.head(15).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['feature']:25s}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance_df.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Top 20 Feature Importance (CatBoost)')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting CatBoost feature importance: {e}\")\n",
    "    else:\n",
    "        print(\"No CatBoost trainer available for feature importance\")\n",
    "else:\n",
    "    print(\"CatBoost not found in trained models\")\n",
    "\n",
    "# Model performance comparison\n",
    "print(\"\\n=== FINAL MODEL COMPARISON ===\")\n",
    "\n",
    "# Create results DataFrame from scores dictionary\n",
    "all_results = []\n",
    "for model_name, model_scores in scores.items():\n",
    "    if isinstance(model_scores, list) and len(model_scores) > 0:\n",
    "        all_results.append({\n",
    "            'Model': model_name,\n",
    "            'Mean_CV_Score': np.mean(model_scores),\n",
    "            'Std_CV_Score': np.std(model_scores),\n",
    "            'Min_CV_Score': np.min(model_scores),\n",
    "            'Max_CV_Score': np.max(model_scores)\n",
    "        })\n",
    "\n",
    "if all_results:\n",
    "    final_scores = pd.DataFrame(all_results).sort_values('Mean_CV_Score', ascending=False)\n",
    "    print(final_scores.to_string(index=False, float_format='%.6f'))\n",
    "    \n",
    "    # Save detailed results\n",
    "    final_scores.to_csv('model_performance_summary.csv', index=False)\n",
    "    print(\"\\nDetailed results saved to 'model_performance_summary.csv'\")\n",
    "else:\n",
    "    print(\"No valid model scores found for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ensemble_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final ensemble recommendations\n",
    "print(\"\\n=== ENSEMBLE RECOMMENDATIONS ===\")\n",
    "\n",
    "# Find best single model\n",
    "best_single_model = scores.mean().idxmax()\n",
    "best_single_score = scores.mean().max()\n",
    "\n",
    "print(f\"Best single model: {best_single_model} (CV: {best_single_score:.6f})\")\n",
    "\n",
    "# Compare with ensemble\n",
    "if 'WeightedAverage' in scores.columns:\n",
    "    ensemble_score = scores['WeightedAverage'].mean()\n",
    "    improvement = ensemble_score - best_single_score\n",
    "    print(f\"Weighted ensemble score: {ensemble_score:.6f}\")\n",
    "    print(f\"Improvement over best single model: {improvement:.6f} ({improvement/best_single_score*100:.2f}%)\")\n",
    "\n",
    "if 'StackingEnsemble' in scores.columns:\n",
    "    stacking_score = scores['StackingEnsemble'].mean()\n",
    "    improvement = stacking_score - best_single_score\n",
    "    print(f\"Stacking ensemble score: {stacking_score:.6f}\")\n",
    "    print(f\"Improvement over best single model: {improvement:.6f} ({improvement/best_single_score*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🏆 FINAL MODEL PERFORMANCE SUMMARY & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive results DataFrame\n",
    "all_results = []\n",
    "for model_name, model_scores in scores.items():\n",
    "    if isinstance(model_scores, list) and len(model_scores) > 0:\n",
    "        mean_score = np.mean(model_scores)\n",
    "        std_score = np.std(model_scores)\n",
    "        all_results.append({\n",
    "            'Model': model_name,\n",
    "            'CV_Score': mean_score,\n",
    "            'CV_Std': std_score,\n",
    "            'Stability': 'High' if std_score < 0.01 else 'Medium' if std_score < 0.02 else 'Low'\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(all_results).sort_values('CV_Score', ascending=False)\n",
    "\n",
    "print(\"\\n📊 ALL MODEL RESULTS (Ranked by Performance):\")\n",
    "print(\"-\" * 70)\n",
    "for idx, row in results_df.iterrows():\n",
    "    rank_emoji = \"🥇\" if idx == 0 else \"🥈\" if idx == 1 else \"🥉\" if idx == 2 else \"📈\"\n",
    "    print(f\"{rank_emoji} {row['Model']:<20} | Score: {row['CV_Score']:.6f} ± {row['CV_Std']:.6f} | Stability: {row['Stability']}\")\n",
    "\n",
    "# Identify best models\n",
    "best_model = results_df.iloc[0]\n",
    "best_ensemble = results_df[results_df['Model'].str.contains('Ensemble|Stacking|Voting', case=False, na=False)]\n",
    "\n",
    "print(f\"\\n🎯 BEST OVERALL MODEL:\")\n",
    "print(f\"   {best_model['Model']} - Score: {best_model['CV_Score']:.6f}\")\n",
    "\n",
    "if not best_ensemble.empty:\n",
    "    best_ens = best_ensemble.iloc[0]\n",
    "    print(f\"\\n🤖 BEST ENSEMBLE MODEL:\")\n",
    "    print(f\"   {best_ens['Model']} - Score: {best_ens['CV_Score']:.6f}\")\n",
    "\n",
    "# Submission recommendations\n",
    "print(f\"\\n🚀 SUBMISSION RECOMMENDATIONS:\")\n",
    "print(f\"   1st Choice: sub_{best_model['Model']}_{best_model['CV_Score']:.6f}.csv\")\n",
    "\n",
    "if not best_ensemble.empty and best_ensemble.iloc[0]['Model'] != best_model['Model']:\n",
    "    best_ens = best_ensemble.iloc[0]\n",
    "    print(f\"   2nd Choice: sub_{best_ens['Model']}_{best_ens['CV_Score']:.6f}.csv\")\n",
    "\n",
    "if len(results_df) > 2:\n",
    "    third_best = results_df.iloc[2]\n",
    "    print(f\"   3rd Choice: sub_{third_best['Model']}_{third_best['CV_Score']:.6f}.csv\")\n",
    "\n",
    "print(f\"\\n🎉 ANALYSIS COMPLETE! Submit the highest scoring file!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2826be89",
   "metadata": {
    "papermill": {
     "duration": 0.063245,
     "end_time": "2025-07-10T07:19:12.826170",
     "exception": false,
     "start_time": "2025-07-10T07:19:12.762925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ed80e8",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2025-07-10T07:19:12.953126Z",
     "iopub.status.busy": "2025-07-10T07:19:12.952801Z",
     "iopub.status.idle": "2025-07-10T07:19:13.646116Z",
     "shell.execute_reply": "2025-07-10T07:19:13.645055Z"
    },
    "papermill": {
     "duration": 0.758833,
     "end_time": "2025-07-10T07:19:13.647994",
     "exception": false,
     "start_time": "2025-07-10T07:19:12.889161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enhanced Model Evaluation\n",
    "print(\"\\n=== MODEL PERFORMANCE SUMMARY ===\")\n",
    "scores_df = pd.DataFrame(scores)\n",
    "mean_scores = scores_df.mean().sort_values(ascending=False)\n",
    "std_scores = scores_df.std()\n",
    "\n",
    "print(\"\\nModel Rankings (by mean CV score):\")\n",
    "for i, (model, score) in enumerate(mean_scores.items(), 1):\n",
    "    std = std_scores[model]\n",
    "    print(f\"{i:2d}. {model:20s}: {score:.6f} ± {std:.6f}\")\n",
    "\n",
    "# Calculate ensemble diversity\n",
    "print(\"\\n=== ENSEMBLE DIVERSITY ANALYSIS ===\")\n",
    "if len(oof_pred_probs) > 1:\n",
    "    oof_df = pd.DataFrame(oof_pred_probs)\n",
    "    correlation_matrix = oof_df.corr()\n",
    "    \n",
    "    print(f\"Average correlation between models: {correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].mean():.4f}\")\n",
    "    print(f\"Min correlation: {correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].min():.4f}\")\n",
    "    print(f\"Max correlation: {correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].max():.4f}\")\n",
    "\n",
    "scores = scores_df\n",
    "order = mean_scores.index.tolist()\n",
    "min_score = mean_scores.min()\n",
    "max_score = mean_scores.max()\n",
    "padding = (max_score - min_score) * 0.5\n",
    "lower_limit = min_score - padding\n",
    "upper_limit = max_score + padding\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, scores.shape[1] * 0.4))\n",
    "\n",
    "boxplot = sns.boxplot(data=scores, order=order, ax=axs[0], orient='h', color='grey')\n",
    "axs[0].set_title('Fold Accuracy')\n",
    "axs[0].set_xlabel('')\n",
    "axs[0].set_ylabel('')\n",
    "\n",
    "barplot = sns.barplot(x=mean_scores.values, y=mean_scores.index, ax=axs[1], color='grey')\n",
    "axs[1].set_title('Average Accuracy')\n",
    "axs[1].set_xlabel('')\n",
    "axs[1].set_xlim(left=lower_limit, right=upper_limit)\n",
    "axs[1].set_ylabel('')\n",
    "\n",
    "for i, (score, model) in enumerate(zip(mean_scores.values, mean_scores.index)):\n",
    "    color = 'cyan' if 'logistic' in model.lower() or 'weighted' in model.lower() else 'grey'\n",
    "    barplot.patches[i].set_facecolor(color)\n",
    "    boxplot.patches[i].set_facecolor(color)\n",
    "    barplot.text(score, i, round(score, 6), va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aad7eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T07:19:13.779125Z",
     "iopub.status.busy": "2025-07-10T07:19:13.778596Z",
     "iopub.status.idle": "2025-07-10T07:19:13.786481Z",
     "shell.execute_reply": "2025-07-10T07:19:13.785238Z"
    },
    "papermill": {
     "duration": 0.076013,
     "end_time": "2025-07-10T07:19:13.788658",
     "exception": false,
     "start_time": "2025-07-10T07:19:13.712645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('catboost_info', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ecfe7",
   "metadata": {},
   "source": [
    "# 🎯 IMPROVEMENTS SUMMARY\n",
    "\n",
    "## ✅ Key Fixes Applied:\n",
    "\n",
    "### 1. **Missing Value Handling**\n",
    "- Added `SimpleImputer` for robust missing value handling\n",
    "- Fixed the `ValueError: Input X contains NaN` error\n",
    "- Proper imputation before feature engineering\n",
    "\n",
    "### 2. **Variable Definition Issues**\n",
    "- Fixed `NameError: name 'X_engineered' is not defined`\n",
    "- Ensured proper data flow from preprocessing to feature engineering\n",
    "- Updated all model training to use engineered features\n",
    "\n",
    "### 3. **Enhanced Configuration**\n",
    "- Updated paths for Kaggle environment\n",
    "- Added missing value handling configuration\n",
    "- Disabled polynomial features to avoid NaN issues\n",
    "- Optimized settings for Kaggle runtime\n",
    "\n",
    "### 4. **Robust Model Training**\n",
    "- Added manual cross-validation as backup for koolbox\n",
    "- Updated all models to use engineered features\n",
    "- Added error handling for missing packages\n",
    "\n",
    "### 5. **Feature Engineering Improvements**\n",
    "- 6 new interaction features for personality prediction\n",
    "- Safe division to avoid mathematical errors\n",
    "- Comprehensive missing value checks\n",
    "\n",
    "## 🚀 Expected Results:\n",
    "- **No more NaN errors** - Robust missing value handling\n",
    "- **No more undefined variables** - Proper data flow\n",
    "- **Better performance** - Enhanced feature engineering\n",
    "- **Kaggle compatibility** - Proper paths and runtime optimization\n",
    "\n",
    "## 📝 Next Steps:\n",
    "1. Run all cells sequentially\n",
    "2. Check for any remaining errors\n",
    "3. Download generated submission files\n",
    "4. Submit the best performing ensemble\n",
    "\n",
    "**The notebook should now run successfully on Kaggle! 🎉**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "high_impact_improvements",
   "metadata": {},
   "source": [
    "# 🎯 High-Impact Performance Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced_feature_selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ADVANCED FEATURE SELECTION & ENGINEERING ===\")\n",
    "\n",
    "# 1. FEATURE SELECTION BASED ON IMPORTANCE\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "def advanced_feature_selection(X, y, X_test, top_k=50):\n",
    "    \"\"\"Select most important features using multiple methods\"\"\"\n",
    "    \n",
    "    print(f\"Original features: {X.shape[1]}\")\n",
    "    \n",
    "    # Method 1: Mutual Information\n",
    "    mi_selector = SelectKBest(mutual_info_classif, k=top_k)\n",
    "    X_mi = mi_selector.fit_transform(X, y)\n",
    "    X_test_mi = mi_selector.transform(X_test)\n",
    "    mi_features = X.columns[mi_selector.get_support()]\n",
    "    \n",
    "    # Method 2: Extra Trees Feature Importance\n",
    "    et_selector = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "    et_selector.fit(X, y)\n",
    "    \n",
    "    # Get top features by importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': et_selector.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    top_features = feature_importance.head(top_k)['feature'].tolist()\n",
    "    X_et = X[top_features]\n",
    "    X_test_et = X_test[top_features]\n",
    "    \n",
    "    print(f\"Selected {top_k} features using mutual information\")\n",
    "    print(f\"Selected {top_k} features using extra trees\")\n",
    "    \n",
    "    return {\n",
    "        'mutual_info': (X_mi, X_test_mi, mi_features),\n",
    "        'extra_trees': (X_et, X_test_et, top_features),\n",
    "        'importance_df': feature_importance\n",
    "    }\n",
    "\n",
    "# Apply feature selection\n",
    "feature_selection_results = advanced_feature_selection(X_engineered, y, X_test_engineered, top_k=40)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_selection_results['importance_df'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pseudo_labeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== PSEUDO-LABELING FOR PERFORMANCE BOOST ===\")\n",
    "\n",
    "def create_pseudo_labels(models_dict, X_test, confidence_threshold=0.9):\n",
    "    \"\"\"Create pseudo-labels from high-confidence predictions\"\"\"\n",
    "    \n",
    "    # Get predictions from best models\n",
    "    predictions = []\n",
    "    for name, pred in models_dict.items():\n",
    "        if name in ['CatBoost', 'XGBoost', 'LightGBM (gbdt)', 'StackingEnsemble']:\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    if len(predictions) == 0:\n",
    "        print(\"No suitable models found for pseudo-labeling\")\n",
    "        return None, None\n",
    "    \n",
    "    # Average predictions\n",
    "    avg_pred = np.mean(predictions, axis=0)\n",
    "    \n",
    "    # Select high-confidence samples\n",
    "    high_conf_extrovert = avg_pred <= (1 - confidence_threshold)  # Very confident extrovert\n",
    "    high_conf_introvert = avg_pred >= confidence_threshold        # Very confident introvert\n",
    "    \n",
    "    pseudo_indices = high_conf_extrovert | high_conf_introvert\n",
    "    pseudo_labels = (avg_pred > 0.5).astype(int)\n",
    "    \n",
    "    print(f\"High-confidence extrovert samples: {high_conf_extrovert.sum()}\")\n",
    "    print(f\"High-confidence introvert samples: {high_conf_introvert.sum()}\")\n",
    "    print(f\"Total pseudo-labeled samples: {pseudo_indices.sum()}\")\n",
    "    \n",
    "    if pseudo_indices.sum() > 0:\n",
    "        return X_test[pseudo_indices], pseudo_labels[pseudo_indices]\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Create pseudo-labels\n",
    "X_pseudo, y_pseudo = create_pseudo_labels(test_pred_probs, X_test_engineered)\n",
    "\n",
    "if X_pseudo is not None:\n",
    "    print(f\"\\nCreated {len(X_pseudo)} pseudo-labeled samples\")\n",
    "    print(f\"Pseudo-label distribution: {np.bincount(y_pseudo)}\")\n",
    "else:\n",
    "    print(\"No high-confidence pseudo-labels created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced_stacking",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== ADVANCED MULTI-LEVEL STACKING ===\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def create_advanced_stacking(oof_preds, test_preds, y, n_levels=3):\n",
    "    \"\"\"Create multi-level stacking with different meta-learners\"\"\"\n",
    "    \n",
    "    current_oof = pd.DataFrame(oof_preds)\n",
    "    current_test = pd.DataFrame(test_preds)\n",
    "    \n",
    "    meta_learners = [\n",
    "        ('ridge', RidgeClassifier(random_state=42)),\n",
    "        ('svm', SVC(probability=True, random_state=42, kernel='rbf')),\n",
    "        ('logistic', LogisticRegression(random_state=42, max_iter=1000))\n",
    "    ]\n",
    "    \n",
    "    level_results = {}\n",
    "    \n",
    "    for level in range(n_levels):\n",
    "        print(f\"\\nTraining Level {level + 1} meta-learners...\")\n",
    "        \n",
    "        level_oof = np.zeros((len(y), len(meta_learners)))\n",
    "        level_test = np.zeros((len(current_test), len(meta_learners)))\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42 + level)\n",
    "        \n",
    "        for meta_idx, (meta_name, meta_model) in enumerate(meta_learners):\n",
    "            fold_models = []\n",
    "            \n",
    "            for fold, (train_idx, val_idx) in enumerate(cv.split(current_oof, y)):\n",
    "                X_train_meta = current_oof.iloc[train_idx]\n",
    "                y_train_meta = y.iloc[train_idx]\n",
    "                X_val_meta = current_oof.iloc[val_idx]\n",
    "                \n",
    "                # Train meta-learner\n",
    "                meta_clone = clone(meta_model)\n",
    "                meta_clone.fit(X_train_meta, y_train_meta)\n",
    "                \n",
    "                # Predict validation\n",
    "                if hasattr(meta_clone, 'predict_proba'):\n",
    "                    val_pred = meta_clone.predict_proba(X_val_meta)[:, 1]\n",
    "                else:\n",
    "                    val_pred = meta_clone.decision_function(X_val_meta)\n",
    "                    val_pred = (val_pred - val_pred.min()) / (val_pred.max() - val_pred.min())\n",
    "                \n",
    "                level_oof[val_idx, meta_idx] = val_pred\n",
    "                fold_models.append(meta_clone)\n",
    "            \n",
    "            # Test predictions\n",
    "            test_preds_meta = []\n",
    "            for model in fold_models:\n",
    "                if hasattr(model, 'predict_proba'):\n",
    "                    pred = model.predict_proba(current_test)[:, 1]\n",
    "                else:\n",
    "                    pred = model.decision_function(current_test)\n",
    "                    pred = (pred - pred.min()) / (pred.max() - pred.min())\n",
    "                test_preds_meta.append(pred)\n",
    "            \n",
    "            level_test[:, meta_idx] = np.mean(test_preds_meta, axis=0)\n",
    "            \n",
    "            # Calculate score\n",
    "            score = accuracy_score(y, (level_oof[:, meta_idx] > 0.5).astype(int))\n",
    "            print(f\"  {meta_name} Level {level + 1} score: {score:.6f}\")\n",
    "        \n",
    "        # Prepare for next level\n",
    "        current_oof = pd.DataFrame(level_oof, columns=[f'{name}_L{level+1}' for name, _ in meta_learners])\n",
    "        current_test = pd.DataFrame(level_test, columns=[f'{name}_L{level+1}' for name, _ in meta_learners])\n",
    "        \n",
    "        level_results[f'level_{level+1}'] = {\n",
    "            'oof': level_oof,\n",
    "            'test': level_test,\n",
    "            'features': current_oof.columns.tolist()\n",
    "        }\n",
    "    \n",
    "    return level_results, current_oof, current_test\n",
    "\n",
    "# Create advanced stacking\n",
    "if len(oof_pred_probs) >= 3:\n",
    "    stacking_results, final_oof, final_test = create_advanced_stacking(\n",
    "        oof_pred_probs, test_pred_probs, y, n_levels=2\n",
    "    )\n",
    "    \n",
    "    # Final ensemble\n",
    "    final_ensemble = np.mean(final_oof.values, axis=1)\n",
    "    final_test_ensemble = np.mean(final_test.values, axis=1)\n",
    "    \n",
    "    final_score = accuracy_score(y, (final_ensemble > 0.5).astype(int))\n",
    "    print(f\"\\nAdvanced Stacking Final Score: {final_score:.6f}\")\n",
    "    \n",
    "    # Save submission\n",
    "    save_submission('AdvancedStacking', X_test, final_test_ensemble, final_score)\n",
    "    \n",
    "    scores['AdvancedStacking'] = [final_score] * CFG.n_folds\n",
    "    oof_pred_probs['AdvancedStacking'] = final_ensemble\n",
    "    test_pred_probs['AdvancedStacking'] = final_test_ensemble\n",
    "else:\n",
    "    print(\"Not enough base models for advanced stacking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bayesian_optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== BAYESIAN ENSEMBLE OPTIMIZATION ===\")\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "    \n",
    "    def bayesian_ensemble_optimization(oof_preds, y, n_trials=100):\n",
    "        \"\"\"Use Bayesian optimization to find optimal ensemble weights\"\"\"\n",
    "        \n",
    "        def objective(trial):\n",
    "            # Suggest weights for each model\n",
    "            weights = []\n",
    "            for i, model_name in enumerate(oof_preds.keys()):\n",
    "                weight = trial.suggest_float(f'weight_{i}_{model_name}', 0.0, 1.0)\n",
    "                weights.append(weight)\n",
    "            \n",
    "            # Normalize weights\n",
    "            weights = np.array(weights)\n",
    "            weights = weights / weights.sum()\n",
    "            \n",
    "            # Create ensemble prediction\n",
    "            ensemble_pred = np.zeros(len(y))\n",
    "            for i, (model_name, pred) in enumerate(oof_preds.items()):\n",
    "                ensemble_pred += weights[i] * pred\n",
    "            \n",
    "            # Suggest threshold\n",
    "            threshold = trial.suggest_float('threshold', 0.3, 0.8)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            binary_pred = (ensemble_pred > threshold).astype(int)\n",
    "            return accuracy_score(y, binary_pred)\n",
    "        \n",
    "        # Create study\n",
    "        study = optuna.create_study(direction='maximize', \n",
    "                                   sampler=optuna.samplers.TPESampler(seed=42))\n",
    "        \n",
    "        # Optimize\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "        \n",
    "        return study.best_params, study.best_value\n",
    "    \n",
    "    # Run Bayesian optimization\n",
    "    if len(oof_pred_probs) >= 2:\n",
    "        best_params, best_score = bayesian_ensemble_optimization(oof_pred_probs, y, n_trials=50)\n",
    "        \n",
    "        print(f\"\\nBayesian Optimization Results:\")\n",
    "        print(f\"Best Score: {best_score:.6f}\")\n",
    "        print(f\"Best Threshold: {best_params['threshold']:.4f}\")\n",
    "        \n",
    "        # Extract weights\n",
    "        weights = []\n",
    "        for i, model_name in enumerate(oof_pred_probs.keys()):\n",
    "            weight = best_params[f'weight_{i}_{model_name}']\n",
    "            weights.append(weight)\n",
    "            print(f\"  {model_name}: {weight:.4f}\")\n",
    "        \n",
    "        # Normalize weights\n",
    "        weights = np.array(weights)\n",
    "        weights = weights / weights.sum()\n",
    "        \n",
    "        # Create final ensemble\n",
    "        bayesian_oof = np.zeros(len(y))\n",
    "        bayesian_test = np.zeros(len(X_test_engineered))\n",
    "        \n",
    "        for i, (model_name, oof_pred) in enumerate(oof_pred_probs.items()):\n",
    "            bayesian_oof += weights[i] * oof_pred\n",
    "            bayesian_test += weights[i] * test_pred_probs[model_name]\n",
    "        \n",
    "        # Save results\n",
    "        save_submission('BayesianEnsemble', X_test, bayesian_test, best_score, best_params['threshold'])\n",
    "        \n",
    "        scores['BayesianEnsemble'] = [best_score] * CFG.n_folds\n",
    "        oof_pred_probs['BayesianEnsemble'] = bayesian_oof\n",
    "        test_pred_probs['BayesianEnsemble'] = bayesian_test\n",
    "        \n",
    "    else:\n",
    "        print(\"Not enough models for Bayesian optimization\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"Optuna not available, skipping Bayesian optimization\")\n",
    "    print(\"Install with: !pip install optuna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_performance_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🚀 FINAL PERFORMANCE SUMMARY WITH HIGH-IMPACT METHODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive results\n",
    "all_results = []\n",
    "for model_name, model_scores in scores.items():\n",
    "    if isinstance(model_scores, list) and len(model_scores) > 0:\n",
    "        mean_score = np.mean(model_scores)\n",
    "        std_score = np.std(model_scores)\n",
    "        all_results.append({\n",
    "            'Model': model_name,\n",
    "            'CV_Score': mean_score,\n",
    "            'CV_Std': std_score,\n",
    "            'Type': 'Advanced' if model_name in ['AdvancedStacking', 'BayesianEnsemble'] else 'Standard'\n",
    "        })\n",
    "\n",
    "if all_results:\n",
    "    results_df = pd.DataFrame(all_results).sort_values('CV_Score', ascending=False)\n",
    "    \n",
    "    print(\"\\n📊 ALL METHODS RANKED BY PERFORMANCE:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for idx, row in results_df.iterrows():\n",
    "        rank_emoji = \"🥇\" if idx == 0 else \"🥈\" if idx == 1 else \"🥉\" if idx == 2 else \"📈\"\n",
    "        type_emoji = \"🔥\" if row['Type'] == 'Advanced' else \"⚡\"\n",
    "        print(f\"{rank_emoji} {type_emoji} {row['Model']:<25} | Score: {row['CV_Score']:.6f} ± {row['CV_Std']:.6f}\")\n",
    "    \n",
    "    # Show improvement\n",
    "    best_score = results_df.iloc[0]['CV_Score']\n",
    "    baseline_score = results_df.iloc[-1]['CV_Score']\n",
    "    improvement = best_score - baseline_score\n",
    "    \n",
    "    print(f\"\\n🎯 PERFORMANCE ANALYSIS:\")\n",
    "    print(f\"   Best Method: {results_df.iloc[0]['Model']} - {best_score:.6f}\")\n",
    "    print(f\"   Baseline: {baseline_score:.6f}\")\n",
    "    print(f\"   Total Improvement: +{improvement:.6f} ({improvement/baseline_score*100:.2f}%)\")\n",
    "    \n",
    "    # Submission recommendations\n",
    "    print(f\"\\n🚀 SUBMISSION RECOMMENDATIONS:\")\n",
    "    for i in range(min(3, len(results_df))):\n",
    "        model = results_df.iloc[i]\n",
    "        print(f\"   {i+1}. sub_{model['Model']}_{model['CV_Score']:.6f}.csv\")\n",
    "    \n",
    "    print(f\"\\n💡 KEY INSIGHTS:\")\n",
    "    advanced_models = results_df[results_df['Type'] == 'Advanced']\n",
    "    if not advanced_models.empty:\n",
    "        avg_advanced = advanced_models['CV_Score'].mean()\n",
    "        avg_standard = results_df[results_df['Type'] == 'Standard']['CV_Score'].mean()\n",
    "        if avg_advanced > avg_standard:\n",
    "            print(f\"   ✅ Advanced methods outperform standard ensembles\")\n",
    "            print(f\"      Advanced avg: {avg_advanced:.6f} vs Standard avg: {avg_standard:.6f}\")\n",
    "    \n",
    "    print(f\"\\n🎉 ANALYSIS COMPLETE! Best score: {best_score:.6f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No results to display\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12738969,
     "isSourceIdPinned": false,
     "sourceId": 91718,
     "sourceType": "competition"
    },
    {
     "datasetId": 7777099,
     "sourceId": 12336995,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 248501546,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 963.3493,
   "end_time": "2025-07-10T07:19:14.979130",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-10T07:03:11.629830",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
